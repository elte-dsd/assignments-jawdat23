{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "re-di implemntaion",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z5JWWd5Lunt",
        "colab_type": "code",
        "outputId": "15f59672-5bda-4f4a-c8ad-d7231dff1db6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "!pip install -U scikit-multiflow"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-multiflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/d0/d73be8c424e116862f26cf4e0f99c41e4f0982519aa7bb923c715f05c166/scikit_multiflow-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (16.3MB)\n",
            "\u001b[K     |████████████████████████████████| 16.3MB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-multiflow) (1.3.3)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-multiflow) (3.1.2)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from scikit-multiflow) (0.25.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-multiflow) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from scikit-multiflow) (0.21.3)\n",
            "Requirement already satisfied, skipping upgrade: sortedcontainers>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from scikit-multiflow) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (2.4.5)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.0->scikit-multiflow) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->scikit-multiflow) (0.14.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=2.0.0->scikit-multiflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.0.0->scikit-multiflow) (42.0.1)\n",
            "Installing collected packages: scikit-multiflow\n",
            "Successfully installed scikit-multiflow-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfUuVg-JOiif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFcQaxVdz8th",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2ec84d0e-3e75-440e-a8ab-82a7a14c3b64"
      },
      "source": [
        "import numpy as np\n",
        "from skmultiflow.data import AGRAWALGenerator\n",
        "from skmultiflow.data import HyperplaneGenerator\n",
        "from skmultiflow.trees.hoeffding_tree import HoeffdingTree\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "class REDI:\n",
        "\n",
        "    def __init__(self, stream, number_of_targets, data_block_size=500, num_of_dynamic_classifiers=10,\n",
        "                 selection_ratio=0.25, stream_length=10000, sudden_drift=False, drift_point=2000, test_point=1000, test_size=100):\n",
        "        self.classes = np.arange(number_of_targets)\n",
        "        print(self.classes)\n",
        "\n",
        "        # params\n",
        "        self.num_of_classes = number_of_targets\n",
        "        self.data_block_size = data_block_size\n",
        "        self.num_of_dynamic_classifiers = num_of_dynamic_classifiers\n",
        "        self.selection_ratio = selection_ratio\n",
        "        self.stream_length = stream_length\n",
        "        self.stream = stream\n",
        "\n",
        "        # extra initializing\n",
        "        self.dynamic_classifiers_weights = np.ones(num_of_dynamic_classifiers) / float(num_of_dynamic_classifiers)\n",
        "        self.static_classifier_weight = 0.5\n",
        "        self.dynamic_classifiers = []\n",
        "        for i in range(num_of_dynamic_classifiers):\n",
        "            self.dynamic_classifiers.append(None)\n",
        "        self.dcir_values = {}\n",
        "        for classe in self.classes:\n",
        "            self.dcir_values[classe] = 0\n",
        "        self.dynamic_classifiers_dcir = []\n",
        "        for i in range(num_of_dynamic_classifiers):\n",
        "            dcir_classifier_values = {}\n",
        "            for classe in self.classes:\n",
        "                dcir_classifier_values[classe] = 0\n",
        "            self.dynamic_classifiers_dcir.append(dcir_classifier_values)\n",
        "        self.static_classifier = None\n",
        "\n",
        "        # Procedure initializing\n",
        "        self.dc_indicator = 0\n",
        "        self.cc_array = [None] * data_block_size\n",
        "        self.resampling_buffer = {}\n",
        "        for classe in self.classes:\n",
        "            self.resampling_buffer[classe] = []\n",
        "\n",
        "        # evaluation paramters\n",
        "        self.test_batch_size = test_size\n",
        "        self.test_point = test_point\n",
        "        self.accuracies = []\n",
        "        self.aucs = []\n",
        "\n",
        "        self.drift_point = drift_point\n",
        "        self.sudden_drift = sudden_drift\n",
        "\n",
        "    def create_new_base_classifier(self):\n",
        "        r_n = self.cc_array[-int(self.selection_ratio * self.data_block_size):]\n",
        "        h_n = {}\n",
        "        h_d = {}\n",
        "        buffer_data = {}\n",
        "        for classe in self.classes:\n",
        "            buffer_data[classe] = []\n",
        "        x_train = []\n",
        "        y_train = []\n",
        "        for classe in self.classes:\n",
        "            h_n[classe] = 0\n",
        "            h_d[classe] = 0\n",
        "            buffer_data[classe] = []\n",
        "        for i in range(len(r_n)):\n",
        "            x_i = r_n[i]\n",
        "            self.reinforcement_weight_adjustment(x_i)\n",
        "            h_n[x_i[1][0]] += 1\n",
        "            h_d[x_i[1][0]] += 1\n",
        "            buffer_data[x_i[1][0]].append(x_i)\n",
        "        classifier = HoeffdingTree()\n",
        "        balanced_size = int(self.selection_ratio * self.data_block_size / self.num_of_classes)\n",
        "        for classe in self.classes:\n",
        "            if h_n[classe] < balanced_size:\n",
        "                extra_length = balanced_size - h_n[classe]\n",
        "                if len(self.resampling_buffer[classe]) < extra_length:\n",
        "                    extra_data = self.resampling_buffer[classe]\n",
        "                else:\n",
        "                    extra_data = self.resampling_buffer[classe][-extra_length:]\n",
        "                h_d[classe] += len(extra_data)\n",
        "                for row in extra_data:\n",
        "                    x = row[0][0]\n",
        "                    y = row[1][0]\n",
        "                    x_train.append(x)\n",
        "                    y_train.append(y)\n",
        "        for row in r_n:\n",
        "            x = row[0][0]\n",
        "            y = row[1][0]\n",
        "            x_train.append(x)\n",
        "            y_train.append(y)\n",
        "        X_train = np.array(x_train)\n",
        "        Y_train = np.array(y_train)\n",
        "        classifier.partial_fit(X_train, Y_train, self.classes)\n",
        "        dynamic_classifiers_dcir = {}\n",
        "        for classe in self.classes:\n",
        "            dynamic_classifiers_dcir[classe] = h_d[classe]\n",
        "        for classe in self.classes:\n",
        "            self.resampling_buffer[classe].extend(buffer_data[classe])\n",
        "            self.resampling_buffer[classe] = self.resampling_buffer[classe][-balanced_size:]\n",
        "        return classifier, dynamic_classifiers_dcir\n",
        "\n",
        "    def dcir(self):\n",
        "        number_of_current_classifiers = min(self.num_of_dynamic_classifiers, self.dc_indicator)\n",
        "        dcir = {}\n",
        "        tot = 0\n",
        "        for classe in self.classes:\n",
        "            val = 0\n",
        "            for i in range(number_of_current_classifiers):\n",
        "                val += self.dynamic_classifiers_dcir[i][classe] * self.dynamic_classifiers_weights[i]\n",
        "            dcir[classe] = val\n",
        "            tot += val\n",
        "        for classe in self.classes:\n",
        "            dcir[classe] /= tot\n",
        "        self.dcir_values = dcir\n",
        "\n",
        "    def shift_classifiers(self, dynamic_classifier, dcir_d_v):\n",
        "        for i in range(self.num_of_dynamic_classifiers - 1):\n",
        "            self.dynamic_classifiers[i] = self.dynamic_classifiers[i + 1]\n",
        "            self.dynamic_classifiers_dcir[i] = self.dynamic_classifiers_dcir[i + 1]\n",
        "            self.dynamic_classifiers_weights[i] = self.dynamic_classifiers_weights[i + 1]\n",
        "        classifier_index = min(self.num_of_dynamic_classifiers, self.dc_indicator) - 1\n",
        "        self.dynamic_classifiers_weights[classifier_index] = 1 / float(self.num_of_dynamic_classifiers)\n",
        "        self.dynamic_classifiers_dcir[classifier_index] = dcir_d_v\n",
        "        self.dynamic_classifiers[classifier_index] = dynamic_classifier\n",
        "\n",
        "    def train_on_instance(self, x_new, cc_current_position):\n",
        "        x_i = self.cc_array[cc_current_position]\n",
        "        self.reinforcement_weight_adjustment(x_i)\n",
        "        x = x_i[0]\n",
        "        y = x_i[1]\n",
        "        self.static_classifier.partial_fit(x, y, self.classes)\n",
        "        for i in range(self.num_of_dynamic_classifiers):\n",
        "            if self.dynamic_classifiers[i] is not None:\n",
        "                self.dynamic_classifiers[i].partial_fit(x, y, self.classes)\n",
        "                self.dynamic_classifiers_dcir[i][y[0]] += 1\n",
        "        self.cc_array[cc_current_position] = x_new\n",
        "\n",
        "    def update_classifiers_weights(self):\n",
        "        number_of_current_classifiers = min(self.num_of_dynamic_classifiers, self.dc_indicator)\n",
        "        for i in range(number_of_current_classifiers):\n",
        "            self.dynamic_classifiers_weights[i] *= (\n",
        "                    1 - 1 / float(min(self.num_of_dynamic_classifiers, self.dc_indicator)))\n",
        "\n",
        "    def reinforcement_weight_adjustment(self, x_i):\n",
        "        x = x_i[0]\n",
        "        y = x_i[1][0]\n",
        "        flag = True\n",
        "        for classe in self.classes:\n",
        "            flag = flag and self.dcir_values[classe] == 0\n",
        "        if flag:\n",
        "            return\n",
        "        if self.dcir_values[y] < 1 / float(self.num_of_classes):\n",
        "            for i in range(self.num_of_dynamic_classifiers):\n",
        "                if self.dynamic_classifiers[i] is not None:\n",
        "                    if self.dynamic_classifiers[i].predict(x)[0] == y:\n",
        "                        self.dynamic_classifiers_weights[i] *= (\n",
        "                                1 + 1 / float(self.num_of_dynamic_classifiers))\n",
        "                    else:\n",
        "                        self.dynamic_classifiers_weights[i] *= (\n",
        "                                1 - 1 / float(self.num_of_dynamic_classifiers))\n",
        "            if self.static_classifier is not None:\n",
        "                if self.static_classifier.predict(x)[0] == y:\n",
        "                    self.static_classifier_weight *= (\n",
        "                            1 + 1 / float(self.num_of_dynamic_classifiers))\n",
        "                else:\n",
        "                    self.static_classifier_weight *= (\n",
        "                            1 - 1 / float(self.num_of_dynamic_classifiers))\n",
        "\n",
        "    def normalize_weights(self):\n",
        "        classifiers_number = min(self.num_of_dynamic_classifiers, self.dc_indicator)\n",
        "        total_weight = self.static_classifier_weight\n",
        "        for i in range(classifiers_number):\n",
        "            total_weight += self.dynamic_classifiers_weights[i]\n",
        "        self.static_classifier_weight = self.static_classifier_weight / float(total_weight)\n",
        "        for i in range(classifiers_number):\n",
        "            self.dynamic_classifiers_weights[i] = self.dynamic_classifiers_weights[i] / float(total_weight)\n",
        "\n",
        "    def learning_procedure(self):\n",
        "        processes_counter = 0\n",
        "        for index in range(self.stream_length):\n",
        "            x_new = self.stream.next_sample()\n",
        "            processes_counter += 1\n",
        "            if processes_counter % self.drift_point == 0 and processes_counter >= self.drift_point:\n",
        "                if self.sudden_drift:\n",
        "                    stream.generate_drift()\n",
        "            if processes_counter > self.data_block_size and processes_counter % self.test_point == 1:\n",
        "                self.normalize_weights()\n",
        "                test_set = self.stream.next_sample(self.test_batch_size)\n",
        "                self.evaluate_batch(test_set)\n",
        "            if processes_counter < self.data_block_size:\n",
        "                self.cc_array[processes_counter - 1] = x_new\n",
        "            elif processes_counter == self.data_block_size:\n",
        "                self.cc_array[processes_counter - 1] = x_new\n",
        "                self.static_classifier, _ = self.create_new_base_classifier()\n",
        "                self.dc_indicator = 1\n",
        "                self.dynamic_classifiers[self.dc_indicator - 1] = self.static_classifier\n",
        "            else:\n",
        "                cc_current_position = (processes_counter - 1) % self.data_block_size\n",
        "                self.train_on_instance(x_new, cc_current_position)\n",
        "                cc_current_position = (cc_current_position + 1) % self.data_block_size\n",
        "                if cc_current_position == 0:\n",
        "                    self.dc_indicator += 1\n",
        "                    dynamic_classifier, dcir_d_v = self.create_new_base_classifier()\n",
        "                    if self.dc_indicator <= self.num_of_dynamic_classifiers:\n",
        "                        self.dynamic_classifiers[self.dc_indicator - 1] = dynamic_classifier\n",
        "                        self.dynamic_classifiers_dcir[self.dc_indicator - 1] = dcir_d_v\n",
        "                    else:\n",
        "                        self.shift_classifiers(dynamic_classifier, dcir_d_v)\n",
        "                    self.update_classifiers_weights()\n",
        "                    self.dcir()\n",
        "        for i in range(self.data_block_size):\n",
        "            x_new = self.cc_array[i]\n",
        "            self.train_on_instance(x_new, i)\n",
        "\n",
        "    def predict(self, test_set):\n",
        "        test_set_array = test_set[0]\n",
        "        number_of_current_classifiers = min(self.num_of_dynamic_classifiers, self.dc_indicator)\n",
        "        predict_prop = self.static_classifier.predict_proba(test_set_array) * self.static_classifier_weight\n",
        "        for i in range(number_of_current_classifiers):\n",
        "            predict_prop += self.dynamic_classifiers[i].predict_proba(test_set_array) * \\\n",
        "                            self.dynamic_classifiers_weights[i]\n",
        "        res = np.argmax(predict_prop, axis=1)\n",
        "        props = np.amax(predict_prop,axis=1)\n",
        "        return res, props\n",
        "\n",
        "    def evaluate_batch(self, test_set):\n",
        "        res, prop = self.predict(test_set)\n",
        "        for i in range(len(res)):\n",
        "            if res[i] == 0:\n",
        "                prop[i] = 1- prop[i]\n",
        "        real_val = test_set[1]\n",
        "        accuracy = ((res == real_val) * 1).sum()\n",
        "        auc = roc_auc_score(real_val, prop) * 100\n",
        "        self.accuracies.append(accuracy)\n",
        "        self.aucs.append(auc)\n",
        "        print(\"accuracy for test number\", len(self.accuracies), \" is:\", accuracy)\n",
        "        print(\"auc for test number\", len(self.accuracies), \" is:\", auc)\n",
        "\n",
        "\n",
        "stream = AGRAWALGenerator(classification_function=5, random_state=112, balance_classes=False)\n",
        "# stream = HyperplaneGenerator()\n",
        "number_of_targets = 2\n",
        "stream.prepare_for_use()\n",
        "classifier = REDI(stream, number_of_targets, stream_length=100002, sudden_drift=True, drift_point=33335)\n",
        "classifier.learning_procedure()\n",
        "from matplotlib import pyplot as plt\n",
        "inds = np.arange(1000,100001,1000)\n",
        "plt.plot(inds, classifier.aucs)\n",
        "plt.plot(inds, classifier.accuracies)\n",
        "plt.xlabel(\"instances (k)\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.legend(('auc', 'acc'), loc='lower left')\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1]\n",
            "accuracy for test number 1  is: 65\n",
            "auc for test number 1  is: 80.82415340677275\n",
            "accuracy for test number 2  is: 85\n",
            "auc for test number 2  is: 90.14020805065581\n",
            "accuracy for test number 3  is: 79\n",
            "auc for test number 3  is: 84.79120879120879\n",
            "accuracy for test number 4  is: 73\n",
            "auc for test number 4  is: 82.8125\n",
            "accuracy for test number 5  is: 75\n",
            "auc for test number 5  is: 84.46519524617997\n",
            "accuracy for test number 6  is: 84\n",
            "auc for test number 6  is: 85.65365025466895\n",
            "accuracy for test number 7  is: 75\n",
            "auc for test number 7  is: 83.91265597147951\n",
            "accuracy for test number 8  is: 82\n",
            "auc for test number 8  is: 89.37132519222071\n",
            "accuracy for test number 9  is: 88\n",
            "auc for test number 9  is: 93.62745098039217\n",
            "accuracy for test number 10  is: 83\n",
            "auc for test number 10  is: 87.41215378255477\n",
            "accuracy for test number 11  is: 82\n",
            "auc for test number 11  is: 88.28282828282829\n",
            "accuracy for test number 12  is: 85\n",
            "auc for test number 12  is: 89.10590277777779\n",
            "accuracy for test number 13  is: 87\n",
            "auc for test number 13  is: 91.2484700122399\n",
            "accuracy for test number 14  is: 88\n",
            "auc for test number 14  is: 93.92446633825945\n",
            "accuracy for test number 15  is: 85\n",
            "auc for test number 15  is: 87.84893267651887\n",
            "accuracy for test number 16  is: 86\n",
            "auc for test number 16  is: 93.4782608695652\n",
            "accuracy for test number 17  is: 87\n",
            "auc for test number 17  is: 93.48904505994213\n",
            "accuracy for test number 18  is: 88\n",
            "auc for test number 18  is: 94.125\n",
            "accuracy for test number 19  is: 84\n",
            "auc for test number 19  is: 90.79861111111111\n",
            "accuracy for test number 20  is: 85\n",
            "auc for test number 20  is: 93.56617647058823\n",
            "accuracy for test number 21  is: 86\n",
            "auc for test number 21  is: 89.81729055258467\n",
            "accuracy for test number 22  is: 85\n",
            "auc for test number 22  is: 92.39176124422026\n",
            "accuracy for test number 23  is: 91\n",
            "auc for test number 23  is: 93.13725490196077\n",
            "accuracy for test number 24  is: 88\n",
            "auc for test number 24  is: 94.92643328259767\n",
            "accuracy for test number 25  is: 97\n",
            "auc for test number 25  is: 98.86314886314887\n",
            "accuracy for test number 26  is: 88\n",
            "auc for test number 26  is: 93.12996031746032\n",
            "accuracy for test number 27  is: 90\n",
            "auc for test number 27  is: 94.25133689839573\n",
            "accuracy for test number 28  is: 90\n",
            "auc for test number 28  is: 92.6729986431479\n",
            "accuracy for test number 29  is: 97\n",
            "auc for test number 29  is: 98.66310160427807\n",
            "accuracy for test number 30  is: 95\n",
            "auc for test number 30  is: 97.19967532467533\n",
            "accuracy for test number 31  is: 87\n",
            "auc for test number 31  is: 92.41666666666667\n",
            "accuracy for test number 32  is: 94\n",
            "auc for test number 32  is: 95.67044976881043\n",
            "accuracy for test number 33  is: 90\n",
            "auc for test number 33  is: 96.54166666666667\n",
            "accuracy for test number 34  is: 76\n",
            "auc for test number 34  is: 84.55882352941177\n",
            "accuracy for test number 35  is: 77\n",
            "auc for test number 35  is: 84.55008488964347\n",
            "accuracy for test number 36  is: 76\n",
            "auc for test number 36  is: 90.13299013299012\n",
            "accuracy for test number 37  is: 69\n",
            "auc for test number 37  is: 79.4937794937795\n",
            "accuracy for test number 38  is: 79\n",
            "auc for test number 38  is: 88.49449204406365\n",
            "accuracy for test number 39  is: 81\n",
            "auc for test number 39  is: 91.63636363636364\n",
            "accuracy for test number 40  is: 81\n",
            "auc for test number 40  is: 91.5931063472047\n",
            "accuracy for test number 41  is: 71\n",
            "auc for test number 41  is: 89.92248062015504\n",
            "accuracy for test number 42  is: 82\n",
            "auc for test number 42  is: 92.78492647058823\n",
            "accuracy for test number 43  is: 83\n",
            "auc for test number 43  is: 91.95833333333333\n",
            "accuracy for test number 44  is: 87\n",
            "auc for test number 44  is: 95.40441176470588\n",
            "accuracy for test number 45  is: 84\n",
            "auc for test number 45  is: 93.22916666666666\n",
            "accuracy for test number 46  is: 90\n",
            "auc for test number 46  is: 95.42857142857143\n",
            "accuracy for test number 47  is: 84\n",
            "auc for test number 47  is: 92.7927927927928\n",
            "accuracy for test number 48  is: 82\n",
            "auc for test number 48  is: 94.23701298701297\n",
            "accuracy for test number 49  is: 94\n",
            "auc for test number 49  is: 98.60426929392447\n",
            "accuracy for test number 50  is: 89\n",
            "auc for test number 50  is: 97.02886247877758\n",
            "accuracy for test number 51  is: 87\n",
            "auc for test number 51  is: 98.03646563814867\n",
            "accuracy for test number 52  is: 86\n",
            "auc for test number 52  is: 96.50974025974025\n",
            "accuracy for test number 53  is: 88\n",
            "auc for test number 53  is: 97.25\n",
            "accuracy for test number 54  is: 91\n",
            "auc for test number 54  is: 98.12321501427988\n",
            "accuracy for test number 55  is: 90\n",
            "auc for test number 55  is: 97.25439725439726\n",
            "accuracy for test number 56  is: 94\n",
            "auc for test number 56  is: 98.15529815529815\n",
            "accuracy for test number 57  is: 93\n",
            "auc for test number 57  is: 99.87878787878788\n",
            "accuracy for test number 58  is: 93\n",
            "auc for test number 58  is: 97.51984126984127\n",
            "accuracy for test number 59  is: 91\n",
            "auc for test number 59  is: 98.62719862719864\n",
            "accuracy for test number 60  is: 97\n",
            "auc for test number 60  is: 99.61862705740666\n",
            "accuracy for test number 61  is: 95\n",
            "auc for test number 61  is: 99.6043956043956\n",
            "accuracy for test number 62  is: 90\n",
            "auc for test number 62  is: 98.62626262626263\n",
            "accuracy for test number 63  is: 94\n",
            "auc for test number 63  is: 98.66310160427808\n",
            "accuracy for test number 64  is: 96\n",
            "auc for test number 64  is: 99.83186212694409\n",
            "accuracy for test number 65  is: 96\n",
            "auc for test number 65  is: 99.55357142857143\n",
            "accuracy for test number 66  is: 95\n",
            "auc for test number 66  is: 99.47812123645123\n",
            "accuracy for test number 67  is: 49\n",
            "auc for test number 67  is: 52.32371794871795\n",
            "accuracy for test number 68  is: 77\n",
            "auc for test number 68  is: 74.42977190876348\n",
            "accuracy for test number 69  is: 95\n",
            "auc for test number 69  is: 98.49837662337661\n",
            "accuracy for test number 70  is: 94\n",
            "auc for test number 70  is: 98.79807692307693\n",
            "accuracy for test number 71  is: 84\n",
            "auc for test number 71  is: 88.16425120772948\n",
            "accuracy for test number 72  is: 93\n",
            "auc for test number 72  is: 98.14141414141415\n",
            "accuracy for test number 73  is: 97\n",
            "auc for test number 73  is: 98.74188311688312\n",
            "accuracy for test number 74  is: 96\n",
            "auc for test number 74  is: 99.27884615384615\n",
            "accuracy for test number 75  is: 92\n",
            "auc for test number 75  is: 97.88\n",
            "accuracy for test number 76  is: 88\n",
            "auc for test number 76  is: 94.84702093397746\n",
            "accuracy for test number 77  is: 92\n",
            "auc for test number 77  is: 89.78365384615384\n",
            "accuracy for test number 78  is: 94\n",
            "auc for test number 78  is: 98.24\n",
            "accuracy for test number 79  is: 93\n",
            "auc for test number 79  is: 95.75\n",
            "accuracy for test number 80  is: 96\n",
            "auc for test number 80  is: 98.27931172468988\n",
            "accuracy for test number 81  is: 88\n",
            "auc for test number 81  is: 98.51046698872786\n",
            "accuracy for test number 82  is: 95\n",
            "auc for test number 82  is: 99.19484702093398\n",
            "accuracy for test number 83  is: 97\n",
            "auc for test number 83  is: 99.55555555555556\n",
            "accuracy for test number 84  is: 92\n",
            "auc for test number 84  is: 98.3974358974359\n",
            "accuracy for test number 85  is: 85\n",
            "auc for test number 85  is: 94.75160256410257\n",
            "accuracy for test number 86  is: 95\n",
            "auc for test number 86  is: 98.39935974389756\n",
            "accuracy for test number 87  is: 94\n",
            "auc for test number 87  is: 91.82692307692307\n",
            "accuracy for test number 88  is: 90\n",
            "auc for test number 88  is: 96.07371794871796\n",
            "accuracy for test number 89  is: 95\n",
            "auc for test number 89  is: 97.22222222222223\n",
            "accuracy for test number 90  is: 94\n",
            "auc for test number 90  is: 96.9187675070028\n",
            "accuracy for test number 91  is: 95\n",
            "auc for test number 91  is: 99.27884615384615\n",
            "accuracy for test number 92  is: 91\n",
            "auc for test number 92  is: 98.63508631071859\n",
            "accuracy for test number 93  is: 92\n",
            "auc for test number 93  is: 98.75551987153754\n",
            "accuracy for test number 94  is: 97\n",
            "auc for test number 94  is: 99.91996798719487\n",
            "accuracy for test number 95  is: 92\n",
            "auc for test number 95  is: 97.83653846153845\n",
            "accuracy for test number 96  is: 93\n",
            "auc for test number 96  is: 98.51465274989964\n",
            "accuracy for test number 97  is: 87\n",
            "auc for test number 97  is: 95.77294685990339\n",
            "accuracy for test number 98  is: 96\n",
            "auc for test number 98  is: 96.94002447980415\n",
            "accuracy for test number 99  is: 90\n",
            "auc for test number 99  is: 95.8198051948052\n",
            "accuracy for test number 100  is: 94\n",
            "auc for test number 100  is: 98.8795518207283\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOydeXxcdb3+32fWzGRPJvvSpE3T0oWm\nC4W2YEvZREAQZBOwKCoqF6569V699+rV6/5DRfEigoogigKyymKhQNlp6b63abPvy0wymZnMZJbz\n++N7zuwzmbRJU8g8r1dek0zOzJzZvs/3eT6bJMsyaaSRRhpppBENzXSfQBpppJFGGqcm0gSRRhpp\npJFGXKQJIo000kgjjbhIE0QaaaSRRhpxkSaINNJII4004kI33SdwIrBYLHJNTc10n0YaaaSRxgcK\n27dvH5BluWi84z7QBFFTU8O2bdum+zTSSCONND5QkCSpNZXj0hZTGmmkkUYacZEmiDTSSCONNOIi\nTRBppJFGGmnERZog0kgjjTTSiIs0QaSRRhpppBEXU0YQkiQ9IElSnyRJ+8KuK5Ak6WVJkhqVy3zl\nekmSpLslSToqSdIeSZKWTdV5pZFGGmmkkRqmUkE8CHw06rpvAq/IsjwXeEX5G+BiYK7y8wXg3ik8\nrzTSSCONNFLAlBGELMtvANaoqy8HHlJ+fwi4Iuz6P8kC7wF5kiSVTdW5pZHGBwmBgMyWpkEmuzW/\na8yHw+Ob1PtMIzGaB5w8t6druk9jQjjZhXIlsix3K7/3ACXK7xVAe9hxHcp13URBkqQvIFQG1dXV\nU3emaaRxiuAvW1r59jP7+dNnV/KR+sTFr9tbbfTZ3Wg1Eka9ljNrC8jQa+Me6/b6ufz/3qbV6mL9\nvGIubyjnnPoisowf6NrZhPD4/Bh18V+LkwG3188tD71P84CTpdX5VOSZpu1cJoJp+zTIsixLkjTh\nLZEsy/cD9wOsWLEiPe0ojQ81/AGZ373ZDMBze7oSEsTTOzv5yqO7Iq5bU1fIQ59ZiU4baxT8/KXD\nNPY5uHJpBW80DvDP/T0AmA1airONXLiwlP/82GmT/GxOLgIBmU0He/ndm03s6Rjm0VtX0VCVNy3n\ncufGwzT1OwF4YnsHd5w3d1rOY6I42VlMvap1pFz2Kdd3AlVhx1Uq16WRxozGP/f10GZ1UZFnYuP+\nXsZ8gZhj9nUO8x9P7GFlTQEv3HEOz91+Nt++dAFvHx3kRy8cijl+a7OV37/VzA1nVvOLaxt471vr\n+fMtZ/LNi+dz/cpqJEniH7unxgqRZZlndnWy8oeb+PN7KXV7OC68e2yQ8+96nS88vJ3uYTc5Jj1f\ne2wXbq9/Sh7vq4/u4pr73qVn2B3zv/eaBnng7WZuOmsWq+cU8vftHQQCH4y97ckmiGeBDcrvG4Bn\nwq7/tJLNdBYwHGZFpTFNaLe6ONRjn+7TmLGQZZn73jhGTaGZ7358IcOjXt4+NhBxjNU5xq0Pb6cg\n08A9NyxjQXkOiypyueXsWm5eXcMDbzfzxPaO4PFOj4+vP76bynxTUCHotBrOnmvhi2vn8O1LF3DW\n7EJ8E1jAZFnG7vaOe9ygw8Ntj+zgX/+2i+FRLz998RCDDk/Kj5Mqntjewacf2AIy3H39UjZ/fR13\nXdNAU7+Tn/4zljBPFIMOD8/u7mJrs5WP/99b7GizBf/n8Pj4xt93U11g5psXz+fqFZW0WV1saY4O\nz6aOQEDmFy8d5kDX1H83p8xikiTpr8A6wCJJUgfwP8BPgMckSboFaAWuUQ5/AfgYcBRwAZ+ZqvNK\nI3V855l9tFldvPJv61I6vtfu5i9b2viXc+sw6GZOic2ejiGKso2U5U6ur/xek5U9HcP88BOLWFtf\nRHaGjuf3dHPuvGIAfP4At/91B/0OD4/fuoqibGPE7f/rktM43DPCt57ay5HeETy+AAe67bTbXPzt\n82eRmSDeoNNI+PyxSiUa3cOjPLmjk79v76DN6uLNfz+X8gTe+puN/Xz10V3YR338x0fns35+MR+7\n+03u2nSEH1yxeIKvTHzIsswvNzXyq1caWVNXyG9uWE6uSQ/A2XMtfHrVLP74dgsXLChh9RzLpDwm\nwMb9vfgDMr+6roFfvHyE6+57j0tPL6NzaJSjfQ6srjEeu3UVmUYdH11YxneM+3l8ezur5hRGnLsk\nSSk93uHeEe5+9ShVBWYWlOdM2vOIh6nMYrpeluUyWZb1sixXyrL8B1mWB2VZPk+W5bmyLJ8vy7JV\nOVaWZfk2WZbnyLK8WJbldIvWaYYsy+xqH6J10JXSYgHw/J5u7n6lcUqtg1MNsixz8x/f58t/2THp\nWUb3vXEMS5aBq5ZVYtBpuHBBKRv39+DxCZvkN5uP8fbRQX5w+SKWxPHW9VoN99ywjNrCTH7/VjNP\n7OigbdDFv180nzNnF8Ycr0KnlcZVEG829rPmJ69y58bDSJKIlbRbXTHH+QMyd718hE8/sJWCTAPP\n3r6GL62bw7zSbG48s5pHtrRxpHdkgq9M5P2/1TjA//7jAOt//jq/eqWRq5dX8sebVwbJQcU3L55P\nTaGZbzy+B2dU9pY/IHPPa0exOscmfA7P7+1itiWTjy8p55nb1vCRegubj/TjC8isn1/MvTcs44ya\nAgBMBi2XLinnxb09jLi9+AMyP3juAGf9+JWU1dQ7xwYBWF03eSSXCB/OlIU0ThidQ6PYXMI26Bpy\nU11oHvc2bcoC8etXG/nkikpyMvTj3OKDjx67G6tzDKtzjNeP9LNO2d2DyFwJyDJmQ+Kv2bF+Bzta\nbXxyeWXEDnJf5zCbD/fz9Qvrg5lIl55exhM7OnircYA8s4FfvdLI5Q3lXHNGVaK7pyDTwD+/cg5A\nyjtUnUbCPw5BHOtzEJDh+TvOBuCSu98Kfl5U+PwBPvPg+7zZOMCVyyr4wRWLIl6Lr5xfz1M7O/nB\n8wf502dXJn28Hz5/APuoj59+8vSI6+/ceJjfvn4Mo07DqjmF3HZuHVctq4j7XM0GHd+7fBEbHtjK\n20cHuHBhafB/O9ts3LnxMDkZOm5aVZP0XMIx4PDw7rFBbju3DkmSyDMb+P2GM5Le5uoVlfx1axuP\nb+vgnWODbDrYC8Dmw/1ctbxy3Md899gANYXmk5IJNXN8gDQmhL0dw8HfW63OlG7TYXORZ9Zjc3m5\n//WmqTq1UwoHu4UPbNBpuGtTY1BF2N1eLrn7Ta65792EAcm2QRfX3vce3/j7Hu7a1Bi8vs/u5taH\nt2PJMnLjWbOC16+ps5CToePR99v5yqM7KcvN4PtXLBr3HCVJSpkcALQaDT5/coJwK8HyWksm+WYD\nAEOuyN33/i47bzYO8G8X1PPzq5fEEGV+poE7zpvLG0f62Xy4j2R459ggT+zoYHg0REKBgMxTOztY\nW1/Eru9cyIOfWRlDtNE4s7YAnUZiV/tQxPU728TfnUOxQeZk+Oe+HgIyfGxx6mVbS6vymFOUyf8+\nd4BXD/Xy3csWUJxt5LVxXgMQpLulycqqSbTIkiFNEGnExd7OMIIYjLUO4qHN6mJlTQGXLSnn9281\n0Wef2Jftg4iD3cIe+fqF9exuH2LzkX4CAZmvP7abY/1O9nXa+Uec4qj+EQ83PbAFXyDAxYtKufuV\nRh56pwWHx8dnHnwfm2uMBz9zBnnK4guChC5aWMpLB3rptI3yy2sbpkSl6bUSvkByW9HjFf83aDVB\ngohWEFaFMNbMtSRctD+9qobibCOPhwXS46F/xIMvIPPqod7gdXs6h+m1e7i8oRyTIbUahwy9lgXl\nOUFCUKESRufQaEr3o+L5Pd3MLspkfml2yreRJIlbzp5NdoaO329Ywc1ralk3r4g3jvSPa+fu7Rxm\nxONj9ZzEFuFkIk0QacTF3s5hTivLwajT0Do4voKQZZk2q4vqAjPfuHCe8J7DdsUfVhzqGaEy38TN\nq2upyDPxy5ePcO/rx3jpQC//fclpzC/N5pebGiO++IIEttJrd/PAzWfw6+uXcsGCEr77j/1c/dt3\nOdQzwj03LGNRRW7M4122pByA29fPZYXia082tBqJgEzSVEyPz49OI6HTajAZtBh1GmxRCsLqEH8X\nhJFcNAw6kUH17rHBhI/nD8gMKrGBjftCBPHS/h60Gon184vj3i4RllblsadjKMJG26lkHnXaUtsM\nAfSNuNnSPMili8smpNAAPnVmNbu+cyHr54ta4XPnFWN3+9gZpWyiocYfVqUJIo3pgizL7O0cZlm5\nibn52pQURL/Dg9vrZ062l+pCMzecOYvHtrVPeEf2QcPBbjunleVg0Gm4fX0duzuGuXPjYS5bUs4t\nZ9fytQvqaR5w8sQOsUMeHvVy8wNbOdg9wr03LGdZdT46rYZfX7+UM2YVcLDbzo8+sSiYqRSNc+Za\neOrLq/nXeIVWLitMQqBcpxGLnT/Jfbm9gYgq7XyzAVtUgFcljPxMhSCcg3HPb/UcC1bnGId64ger\nba4x/AEZs0HL60f6GR0TQfqXDvRyZm1BhMpKCFcorbShOg/nmJ/GPvF4vXY3XcNudBop6ed1xO1l\n/c83c/4vXuf+N47x1y3tBGS45PTy8R8fwO8Ddyg1VasJkcqauRZ0GonXDiW3md49Nsj80mwsWcak\nx00W0gSRRgw6bKMMubzcbP8tP/f+ICWCaLe6uFCzjWtfPw8GGrlqWSX+gMyecXZEH2S4vX6a+h2c\nptgLVy2vpNYi7IafXrUYSZK4YEEJS6ryuPuVo3QNjXL9/e+xu2OIX1+/lHPDdr4Zei0PfvYMnr5t\nDdeekbiFjCRJLK3OR6OJ2rG67XDXIth6/wk/L61GLAvJ4hCidUVo+VBjT+GwOsfQaSRyMnTg6INf\nzIeXvxNzX2vqxG74nagaDxX9IyK754qlFYx6/bzR2M+xfgdH+xxcuKAk7m0isOcx+Fk9DIva26VV\n+UAo7qBerqmz0DfiiVuMCPD95w7QMuAk06DlRy8c4q5NR6grzqK+JGv8cwB4+y64ZyXEse9yMvSs\nqMnntcP9wev2dgzzsV+9Gayr8Pj8vN9iPWnqAdIEkUYcqPGHMm8rFb422qyucVM426wu5kntaAJe\n2P4gdcVZSBIc6XUkvI0sy7zZ2P+BbRjX2CsyeeaXiVx0vVbD07et4enb1gQDspIk8fUL6+kcGuWC\nX7xO04CD3284I25Q02zQHX8rCOsx8DoFQZygitBrBfkki0PEUxDRQWqrc4z8TIOwXzq3g38M3rkb\n9j0RcVxZronZlkzePpqcIC49vYxck56N+3t4+YCwmsIzkRJiy30Q8ELPXgBmFZrJN+vZpRJEuw2D\nVsMFC0qQZVHfEY2X9vfw2LYOvrRuDs/8y9ls+tpHuH19Hd++dEHq9lLHNhjpBnv8JhHnzivmYLed\nnmE3bq+frz62iwPddr7yt104PD52tg3h8QUmtYZjPKQJIo0Y7OkYRq+VMI9ZMfuG8Xi9wS9pIrRb\nRymThD/K7r9i0viozDcFZXw8/GbzMW76w1ae2pE8QHmq4qBSZX5aWahYKdekj2mQd3adhdVzCtFo\nJP58y5msTdJw77hhaxGXg0eh9e0TuivV+kiW6hqtIPIz9bExCOcYhaq91LULkKBiBTzzL9C7P+LY\n1XWFbG224o0TpFU/e+W5Js47rZhNB3p5YW83iytyExbmBdGzDzqVsqqBI4Ag7YaqPHa2i535zrYh\nTivPYbYlE4gNVA84PHzryb0sKMvhX8+rB6CuOJt/u3DexN5L5fGDl1FQFeXmw338/KXDHO1z8NXz\n6+mwufjus/t55+gAGgnOnD01sad4SBNEGjHY1znMvNJsNK5+NATIZ4SWcWymNquLWv0QaI3gGoRD\nz1FfnM3RvvgK4tH327hz42EABhwTL046FXCoewSTXkt1QfIaEUmS+P2GFbzxjXOnLLAcJAhDNmx/\nMLXbDHfAkZdCP3aRbaXGILxJLCa3NxBRLZ9nNjAUZTHZXGPBDCe6d4OlHq77Cxiz4W83wGioJcWa\nORacY372dMRakv1KAVlRtpGLFpZid/vY0zEs7CXPCNiSFGbueAi0BsjIhYHDwauXVufT2OdgyDXG\n3o5hllblUZEvyKbTFkkQ3356HyNuH3dd23D8HQK87tB7lIAg5hZnUZFn4ndvNgV7Zf3rYi9fXlfH\n37d38PB7rSyuzDup9UVpgkgjAmqAuqHMDG5hNVmk4XEzmdqsLiq0VpizHnKrYftD1JVk0dTvjEnd\ne2l/D996ci8fUdpLh+e2f5BwsNvOvNLsiGBjIpgNulCwdipgawVzITRcDweejQjKxoUsw8NXwiNX\nh37uXQNDbcHur+MpiEiLSc/QqDfCihx0jlGgPufuXVDeANmlcM2fxGL5/u+Dx541uxBJgrePDsY8\nVv+IB7NBS6ZRx0fmFmFSHvfChaXw0n/DHy+Of5JjLtjzKCy4HEpPh/7QwtxQlYcsw+PbOhj1+lla\nnUdpbgaSFKkghke9vLivh8+dU8u8CaSyxsB6DGTle5CAICRJYt28Io71O6nMN/HfDaNw7yq+Mm+Q\nJZW52Fzek5beqiJNEGlEoN06yvCol+WWUNfLYs3IuIHqdquLosAA5FXBsk9D8+s0ZNoY8wdoDWvB\n0Gd3c/tfd7K4Mo97b1hGnlmP/RQmiESxF1mWOdRj57SyE1g0JhO2FsivgWUbwO+B3X9LfnzrO2JH\nvf7b8LlX4cYnIeCDR2/EIIsde7IYhMcXiLSYzAb8ARm7OxRPsqkEMdIrvPeyBvGP6rPAMhc6d4Ru\nn2lgQVlO3DhE/4gn2GfKZNBy0cIS6kuyqC/OhMZNwtP3xbFADzwjNjnLNojHGzgSjM+orUkeercF\nEIFro05LUZYxQkGohZDJWpOkBJUUjDkRRBWNSxaXYdBp+Nknl2ByihE5uoHD/PK6pSwsz+GSCRTk\nTQbSBJFGBPZ0Com/OC/0hZub6YpY5KPh9vpx2K2YAk7IqYClN4CkYfngPwBoDOu18/axATy+AD+8\nYhGZRh05GfppVxDH+h2c/dNXORoVL+m1uzn9uy+xUZmVEPk/DzaXl/mlU9ssLWXYWiBvFpQugorl\nwlpJFqze/iAYc+GsL0Plcqg7D678HXTvZsW+7wNycgXhjVYQkdXU/oDM0KhXqKbu3eKgsiWhOyhr\nUOISIayps7CzbSiYxqqif8RDUVha50+uOp0nvrQaydYMdiV+5eglBjsegoI5UHM2WOaBewicIkso\n16RnTlEmHbZRCjMNVBUIe6ki3xShINSOqSe8EVBJYe4FCRUEiP5K+757kSAkp0KWthZqLZk8f8c5\ncWtjphJpgkgjAns7hzFoNczKCBHCbPMobUksps6hUUrV6bK5lZBTDvUfxXL07+jw0RiWybS12UpO\nhi4Y2M01TT9BvHqwjw7bKH/d2h5x/dM7Oxnx+Hh6Z2zWSbwA9bQh4IfhdqEgQOyY+w9B+9b4x7us\nYnd9+tVgCIufzPsorP0ms9qf4UbtpqQxCMnrZPnY+0ESys8Uvria6jrkGkOWocCsF/YSEpSF9VEq\nb4CRLpH+qmD1nELG/AHeb4m0x/odnohOtRl6LdkZemh6LXTQSBSJ9x+Gtndh+QaQJKEgIGJxXlot\n0l0bqvJEJtKRjdTmRFpMB7rtWLKMFGdniCvatojYTTR69onHTISBI8J6LVsCzr6I+Es0gnEO9bVR\nYxfTgDRBpBGBLU1W5pdlox8NSf0qgyNpkLrd6qJczWDKqRCXp1+DxtnH+txuGsMC1VuarKysLQj6\n9qcCQWxrFQvSM7u6IuIlTynE8MaR/pjc+ENKi40T8qUnC/ZOYQ+pBLHoKhGYPfRc/OP3PCZsqGUb\nYv+39j+wWlbwee3zSRXE6tHXuaPnP0UKKQSL1dRMJvWyIMsolEJhnQhOq1DVhKougJVKnyS1WlhF\nuMUUgabNICkqJpogjmwUl6dfJy6L5il3Fh6ozgtdWpvgkWv44sCP6RlyBau6D3TZQy21ZVnEah66\nDEbDgun9R+CBj4rsrEQYOAxF9ULJAAyk0GVAUTsMTV935DRBpBHE7vYhdrUP8fEl5aEPpzGXUu0I\nw6PemDx3Fe1WF6WSqiAUgiiYDcDiHFewnXPfiJumAScra0OZPNNNELIss711iOJsIwMOD28pHvjB\nbjuHekb4SH0RzjE/W5ojF62D3XYq8kwxLaWnBeoOUyUIY5ZYkOMtQrIs7KXyZZE7ehUaDa7sWjKk\nsaQxCJNfseM2/ie0vB1jMVmd4j0tMCsWU3lD5B2UKo8dZjOZDTrml2VzoDtUbezx+Rke9UZYTIBQ\nTc1vQt354u9oi2m4Q/j92UohXU4F6DMjXpOz6yxkG3WsrS8O7tbrh97kCzzJgEMUzDX2jbBAVYkj\n3SKmYW2CJz8vCt7cdnj0BhgbgZ49olo6GoEADBwV5KAqmWRqQ4X6HUwriDROBfzhrWayjDquPaNK\nfDj1ZsifRT4im0kNVHfYXLwU5su3WV1Uaa3ISJCtBNGyRAHTXLOTpgGRyfR+s5DVK2tDAb9csz6l\naWRThTariwGHhy+tm0OuSR9UDU/v6kSnkfjxlYsx6jS8cjCyBcIpF6AGyA91fsVSH5HWGUTH+9B/\nUFgviaDRoyWQtJLaEFBsmIJaeHwDBX6xmNkUYrA6RQzLorGLOEF4/AEgI0eQWHdkHGJOURbHwhSn\nmgIdoyC6d4uYwuJPChUxEjWA0t4ZUrMQspnCXpNZhZns/d5FLK7MDfr99oLFfFX3BPa9L3Cs34HX\nL4feZ3VRX3glNL4Em38MT38JBo8JNeZzx3/Nh9vBNyoeP79GqLskcYggVIIYtUUqlpOINEGcgvD6\nA3Fn2ybC49vaOetHr7AvrAPrRNE1NMoLe7u59owq4e86+yHTAplFZPvEwt5qdTE65mfDA1v5wsPb\ng4/XZnVRZxxCyi4FrbKjzrSApKVab2fMF6DdNsqW5kHMBg2Lep4U+esIBeH2BoJDcE42trWI57Zq\nTiGXnl7Gxv092N1entnZxdr6IiryTJxdZ2HTwd5gRtOBLjuNfY6gh03jptR2hBOBywpbfwf+FMjT\n1iIWyZywWQKWenG9N+pztP0hsZNedFXi+9Pq0ONLOjRIH3Dj1RjhukfAO0rOs7egl/xBa0lVEMUO\nZcRnWUPsnZQtibCYQBBE59BoMFCtFsnNGTsELW+FDmx+XVzOXgdZJSJTKhzDHSE1q8JSnziDyCUU\n4sCF/8dBuZpZm++gtVEU8y1ULSZVfXz0x9BwA7zx/4SNd+H3YZViL0UF3iNuVzQPNFpF3aVAEI4+\n8V5BpM0U8MOL3xSV2VOMNEFMEU5kuthvXjvG+b94fdxF0+sP8D/P7OMbf99Dj90dN9smVTz0bgsB\nWebm1TXiCkcfZBZDVjFGj/jytA06+fGLBznW78Rs0PLLTeJD3mYdpUpri9yxabSQVUyJRux8jvSO\nsLXZyifKbOie/2owDTNHsWimy2ba1mojO0NHfXE2Vy6rwO0N8N1n99Njd3PFUvF8zjuthA7baLBt\nyI9fPEiuSR+a1fDMl+G1H03uie3+G7zw9bi9i2JgaxHpxdqweQtF80TevTVsLocsw5EX4bRLI+MB\nUZA0OrQEksYgDIFRvBqTeJwLv4/UuY0VGV0xMYhsm1IxHc/OKmsQu2tnyL6bUyT6GjUNiNe6f8SD\nhgBL3r0D/nRFKPDetBmKF0JWsbCRxlMQIGIA9g7wxCneVAiiqKKWW71fRet1Yj74KBl6DbUWpdfS\nwGGR+ZVVApf8HGrXwvLPiEywwjowZMUoouDtQBCUepmSghiAimXi93CbaaARttybWhzjBJEmiCnC\nNfe9y09ePL4B6S/u68bh8dEVNbzE7vZyz2tHuXPjIX7y4iGuu/89Hnq3lc+fU8uCshy2Rg1C9/oD\nfOFP29jSFFt8FA6nx8dft7Tx0UWlVKlVwc4B8eXLLELjGqA4y8CTOzv507ut3HJ2LV9aO4dNB/vY\n2zFMu9VFiTwQu2PLKiHXJ87p/WYrh3pGWGVRrAllp6V6+NNVC7G91coypfndsup8ZhWaeXJHJ1lG\nHeefJvzr804TLRA2HezljSP9vNk4wO3r54pzl2Wx20/lCz8RqAvNe7+BPY8nP9bWGoo/qAhm7YQp\nm+EOsRBWJp94Jml16PAnnE3g9Qcw4cGnVdpcFC8AoMroCmYxDTrGyDRo0ffuFvGojDjpmWpcImxR\nnVMsdszH+kXWXP+Ih7Wa3Ric3cKaeezT4vm2vQez14obZZVGxiB8HqGAc6Oms6kL9GCchdU1CHoz\n2dm52I3l9GfMItu6n3mlOaFCyIEj4nWVJNCbYMOzcNkvxd8aDZQujlFEwduZCoSqBkGq8dRdOMac\noreW+l6FE4T6ekXHdaYAaYKYArjGfGxrtQV7zE8EnUOjwbbH0TN+/7mvhzs3Hubezcd44O1mWgac\n/PLaBv7rkgWcObuAXe1DEapje6uNlw708vSu2IE14XhiRwd2t49bzq4NXensC1pM+NycViDR1O9k\nfmk237hoHjevqSHXpOd7/9iPw+Ml19sXaXEAZJehc/ZSkWcKtrtelKXs3rojCWI6FMSwy8uRXgfL\nZwmrSJIkPqGoho8uKg0OoSnJyWBxRS4vH+jlxy8eoqrAxI1nKR1XvS7RCG7waPwA5fGiaxfMOQ+q\nV8OztwcbzcWFWiQXjkKVIMIWw2A9QvKFJUgQCRSExxfAjBufTiEIs1j4yg2uYJDa5hqjIMsAXbsT\nP54aqA4jiJrCTCSJYByif8TD9dpXkTOL4TPPCy/+jxcLv3/2OnGj7NLILCa1GV60gkiWQeQaFJXo\nQEW+maPaOqo8h1kQnqXWfySUDRUPZQ3ifQpEKf/o21nqFXV3LPF9qfGHwjow5Ue2E+naBTpT6D2e\nQqQJYgpwuGcEWRZtsyeKV8P6wbdFEUTLgBO9VuLIDy7myA8uZvu3LwjaICtrCvD4AhFxiM1K6+Dd\nSVpuH+y286tNjSypymOZ6qkHAkJBKBYTwOL8MQw6Db+8riGYh/75c2rZ1mojFyf6gDtWQWSXgKOH\nuuIsbC4vBp2GSq2icvoOgtc9rQShtlFeoRAEwCeXVzKr0Bwx6hOEitjVPsTBbjv/ftF8jDolvVIN\nHvrHJi8dccwpdp2VZ8DVD2OlBqwAACAASURBVIIpDx65Fp74nPh55l9CtoxnBFwDokguHAazyLsP\nj4107wJJAyULkz68pDWgkwL4EygIt9ePGQ9+naI2zSIrrUTnDAtSjzErww3DbYl3uqY8yK+N8O0z\n9Fqq8s0c6xcE4bF1sF67E2npDVC+FC7/P0EAGh3MWi1ulF0qXgOfkmWntPWO+TwWzBaxmnjxonCC\nyDPxtqsSC8MsL1B2+e5hcPSElFk8lDeIDUO0mlSVhwpVyQSb9zXCK/8bSSwOhSAyiwT5RyiI3UKt\naBPPOp8spAliCqCm6XUPj8btTpkMrx3qo6rAhEGroT1qulXroIuqfHOwV0441CZw77eEVIs65/dw\n70hMdSoIhXHtfe9i0Gn4xTVLQm2LR20g+8WHU5HFn1uWxTO3rYmoHN6wuoY8sz62BkJFVik4+5lf\nJIqMllbloRtR1Izsh979J5UgDnbb+fJfttOrjELd1mpFq5FoqA612K7MN/P6N86Nabut2k1LKnMj\n2x24w8h3smymnr2ArPQuKoFr/yIWr87t4mfnw/D+78Sx6s4yWkGA8NzDLaauXVA0P7I4Lg4kjVh4\n/AkC5B5fAJPkIaASREYeSFosmpGwNNcx6g3KImdJsusub4gTqM4MWkzzup9FR0C0bwGRtXTuf8GK\nz4biKFlKKqtT2VwFFUSUotUZRNZVvPcpjCAq801scQuF2KBrEf9XVUey5xKntgOXVZBX+O0K6wBJ\nKIvRIXjkGnjz55HnpSqIrCJB/ipBBAIinfYk2EuQJogpgVqeH5ChewJD0EfH/Lx9dIDz5pdQkW+i\nwxqpQFoGncwqjP/lLso2MtuSyftKHKJ7WFhVZ9Tk4w/I7O+KzHB6++gAN/1hC/mZBh7/4qpgcBAI\nfdGyioSKAPICwzFVw9kZem5bV8dso7JIRnu+2SLVdVGuyEQ5s7ZAfHlzq8T/u3eGCMI19QTx8Hut\nvLC3hxt+v4VBh4ftrTYWlOUEZzckw8LyHG5fX8dPrjo9cljP6BQQRHRrisrl8MU34Y6d4mf2ubDj\nYbHjHEpCEJZ5Iv8+EBCxku5d49pLAJJOIQhfAoJQFISsEoRGA+YCCqSRYAzC6hyjQq/YiVlJRoKW\nNYjnENZccE5RFk39DgJ+P2cNPc8+Y0OwrgaAtf8OH7sz9LeaWq1mMqmVzjlxJr0lChBHKYiD8iwC\nskS1RyGG/qhAczxY6kVqeHgmU7zbGcwiqaD/EDx1ayiRINxGUr+DqoIYahPv9+BRGHOk9D5OBtIE\nMQU42G0PNjLrmMCM23eUPkXnnVZMZb4pwmKSZZnWQRezCjMT3v6MmgK2tdoIBGReV+wltX/9rjCb\nyecPcPtfd1KRZ+LxW1dRmR9FOs4weZup9Lt3RNYBqPjcObXcdZFyTPQXUiGIJflu9FpJ9Lsf7hDN\n2kz50L2b7AyxGA2PTu3QIFmWeeNIP/UlWXTYXNz0h63sah8Kxh/GgyRJ/NuF82Jba4QriCRN2CaE\nrl2CmLMTNGZbfrPIxjn2amyRXDgsc0X+/XC7yPJx9qe089Qoqcp+X/z3xO0VMQhZH/a5MReSK48w\n6vXj9op01xKNUkyXlCBid91zirPw+AIM7NlISaCX7YUfT37CajGcmslk7xRB4XhKyVIv6hai40XO\n8BiECRcZtGkqMPQpsZ+BIyJIHu91VqHRKoHqMIJQyagoilgs9aLdyZF/wtr/ENeF20jRFlPAK9qx\nx+trNYVIE8Qkwx+QOdQzwjlzxaIZbRMlw6uH+jAbtKysLaC6wBxx20HnGA6Pj5oECgLgjNoChke9\nHOkbYfPhfspyM1hTV0hFnondHSEFsbXFitU5xtcuqKc4JyP2jlQyyCwOZV44+2OPQyycBmeX8ISz\nosY/Kn9X6+3s/e5FLK3MFR/ynArxAe/ahV6rIdOgnXKLqWXQRYdtlJvOmsV9N63gaJ8DtzfAiprU\nCCIhVAWRWzWJCkJpjZ1oUtm8j4nA8PYHxaJizBGEG42isKCsuqtNYWGRFIKQ/fEr5z0+P2bJg2wI\n26yYC8kOiM9Yz7Ab15gfi6R85sxJJqAFCSIsk0lVszv+hE3OprvsvOQnrBRl4lAC1cOdsfEHFZZ6\nsdjamkPX+TyiEjpTEIQ6hKg3a37ovAaOiMZ/4/n+ZUuge09orGjPHtBliHhQxHnMEzbrkuth3bdE\nvUM4QTj7RUqtzhgipaFWcT66DGEVngSkCWKS0TroxDXm57zTitFqpJQD1bIs8+qhPs6Za8Go01JV\nYGbI5Q1WGbcMCE92liWxglipxCHeOTrIW0cHWDevCEmSWFKVGxGo3nSgD4NOw0cSTcNSu0hmFonC\nN1N+QoIAxI4tu0zsoMIRlP49ovOns198OXMrhUTuOwg+z6S02+izu3lhbzevH+lne6stpi3IG0fE\n+X+kvoi19UX85oZlnDW7gLPrTnB8ozIzg8ozhN9/guM+GXMJ6yHZQq4zQMOn4PCL0L5FVFDHI5Ng\nMPSw2HlKSirmOAgpiPjviVAQnsgdurkAs1d8xtQahnyGxSKnj7MJCbsdebMiFERdcRYgk939Di/5\nl1OQO07FemaReG6qxWTvjI0/qFCtqnA7R7W3FAVRlW9CksBbfLpQJSO9sYHmRChrEOmpg0dFK5Bt\nf4T5lwobLhyLrxLV15feJd67/JrIJAdnn7B4IUQQthZB9CWLTkqAGuDkPMoMwkGlidviilzKcjNi\nUlWT3a572M1Xzxdf6irF9mm3ulhYnhtslleTxGKqKjBRkmPkD2814/D4WDdPSPsllXm8sLdHzAg2\n63n5YA9r5hSSaUzw9jv7RLaHuivNLE5oMQFixxYdoAbFnpJCOepqa+acCqFMAl7oO0DOJBDE/zy7\nnxf3hVIdLVlGXv362uD0rTeO9DOr0By06M5fUML5qQy8Hw+qxVR5Bux/UpBgMktlPPTuFymQ43nM\nyzaI+c7du+G0y+Ifk2kRVkv/YfEeWOrBkPjzo0JSFh85UZDa68OEB2eEgrBg9IoEiSYlwJzjt4UU\naDIoalJFQaaBBaZhTL5h9sq1LI/XqC8cWp34rKkWk2pjxoOqLNTPIgSL5FSCKMwy8pfPnUlDIBuO\n/QI6toK1GRZ+Yvznolp4h5+Hd/4PCucIEohGxXLxoyK/JlLVOAdC9m5upfg+WpvE+73k2vHPY5KQ\nVhCTjAPdw+g0EnXFWVTmm2hPUUG8clAsouvmiw+FOsayXQlUtw460WokKpLM4JUkiTNqCugcGkWv\nlVij7I7V4Si7O4Y43DtCu3WUCxYkGfauttlQdz2ZRSFVEQ/2OG0NIM4XNyz9UN0hd+0i13Ri/ZgC\nAZl3jg1y8aJSnvjSKn529RIGHB7+8l4bAGO+AO82DfKRuVMwC3p0SOySixXJf6ItN1ItgrLUQc05\n4vdkvrilXlhM3btT9q01OkGqgQR1HR6PB73kR2MMS2wwF6L3DCERCGYgZXptqZFleYNYHMMC/ufm\niGy3vYFairKSKBAVWSWCBMecgrTjbVhAUbVS6LMIIstIeQ4qVs+xYK5eKv7Y/5Swg5IFqFVY5gkL\naNP3hHV17V9E36nxoKayqgrU0RciCK1efGeOvSassJMUf4A0QUw6DnTZqSvOCuZzpxKklmWZZ3Z3\nsXxWfrDvvDrARFUgLYMuKvJM487EVTulrphVQJaiEBZX5KKRRD3Ey/sFEanVwYAY2/juPaG/Hf3B\n7CVASF1nAgURCITiCvGQXRop/UHI//xaUV3brRDECSiIgz12hke9XLCghOWzCvjk8krOmWvhD281\n4/b62dZqxTXm55y5J2gnxYN7CEy5sbntqeLAs6KFhFvpYNq9SyxUiV7PcKjtuqNrIMJRVA9dOyMn\nuo0D1WIKJLCY/EofLU1UDEKS/eTgCtYwZHgGU1QQynn17AletczQhk/WcEiujt/qOxrZZaJYLrgJ\nSWAxafXiM2kPJwhVQUSdqzFbpKQeekH8nQpBaHXCAkKGT9wbG5xOhPwaUUOhWrnRSjS/BrqUCXwn\nKYMJ0gQx6TjYPRLMdKnMN9Nr9+D2Ju+ptKdjmKN9Dq5aFvpQ55r0ZGfogoHq1iQpruE4U+mUun5+\n6MOVadQxtzib3e1DbDrYy5KqPErCg9O7/wbv/Ta0e1EVRPAOihLHIFwDokgs0RcyuzQseNghdlfm\nAuG7Ks3aTjQG8a4yP+CssLGQX15Xx4DDw+Pb2nnjyAA6jcSqqZjnOzok6gCC7aQnSBA7HxaDb576\noiBbtfI4UYA6HAsuFwHOBVckPsZSLzKZIOXceY2S5hpIYDH5PUIhaI1hBKF8XgqkkaDFpHMPRm40\nEkFd8MJsprn+ozTKlXgwpEgQJYIgwm3MRMipiBz6ExWDiDk39fVLJQYBcO5/wuW/SWz9xYPaidfW\nIho0jlpDCgJCKlFrgOLTUr/fE8S0EIQkSf8qSdI+SZL2S5L0FeW6AkmSXpYkqVG5PMH0kpOPQYeH\nHrs72D9eVQFdQ8ltpid2dGDQabjk9FBaoyRJVOWbabe6kGWZ5gFn0viDinml2Tz02ZXctCpyV7mk\nKpetzVZ2dwxzYbj37nGIxX+4LeSBOvsidy+ZxSIYG2/ub6K2BiqySkJtENQGauriV7YEeveTbzyx\nQrn3mqzMKjQHs08AzppdwNLqPO57o4nNh/tYNitfdKmdbLiHREVwsJ30BAjCNwYtb4sMl8PPw+Yf\niVbcqRZB6Qyw7puhYGY8BAu0pJQC1ABarZjtICewmAJuhQAywi0moVxLdU4GHMKCkqIXuUTILBRZ\nYKq9JsuUOg+xN1CLTiORl8rMDaUokyFhKybMYlL/F09BxMsEU9+L3KqU4jeAGN+69IbUjlURHohW\nzyceQZQsDHVMPgk46QQhSdIi4PPASmAJcKkkSXXAN4FXZFmeC7yi/D3lGHZ5eWRL2wl1X1WhBqjV\nCVRq47tkcYgxX4Bnd3dx4YKSmOEzVQWiFmLI5WXE7UtJQQCsrS+KmBcMIg7hVKqpLwgniPDMiSal\nhXJ4gAxCC1C8OESitgYqssuU7CV/bPphWQP4x6iV23CN+RNWnb9zdCA4dCga/oDMluZBVkUNlZck\nidvW1dFhEwWDaxNlbJ0oRodCjeiK5k2sFqJzu8h4ueiHsPgaeONOMRluMj1m1eKInuiWBKqCSBSk\nlseEhaQzRcYgQDTsA6g1uZGQk5NXOMJbf9u7MHis7JNrsGQZIwsTEyG7FJCFnQaJa0hAWJz2rjDF\nPCDIIV5mkPpepGIvnQjylDRYW2tYmnkcgjiJ9hJMj4I4Ddgiy7JLlmUf8DpwJXA58JByzENAEt08\nefjHni7+86m9EWMxjxcHuyPnFFfmR8YR4uHVQ30MubwR9pKK6gIzHbZRmpV50KkoiERYUikC1bMK\nzcwtDvtiq7nXkka0UPY4hBca/uFUf1fjEFvuh+/mwXdzxTQtCFVHRyO7RGTlOPtj0w+VD/ussaNA\nYhXxlUd38atX4rc2PthtZ8Tti7CXVKyfX8y8ErEoHleA2jMCdy+LnEMQDbdiMYFQEInaScdD02bx\nuteeA5f9CkqUHf5kLgK5VaKx2wRaM2jGUxCKxaTPCCMchSDKDUq2nUn5zKeiIEA858GjIhajKIlD\n0pzU7CUIFmXSuV0oXl2S2+VWiM+4Ohc6rIo69ryWAFLyJn2TAb1JkJqtJazNRngMQmmkeZJabKiY\njjTXfcAPJUkqBEaBjwHbgBJZltWm7j1A3BxESZK+AHwBoLq6Ot4hE8KAQ9gmTf1O6ktObELYgW47\npTkZFGSKL1hJdgZ6bfJaiCd2dGDJMsYNoFYVmPH4AmxThrjXWFJTEPEwrzSbPLOeSxaXhXouQSgf\nvO4CaH4jlJIabTGB2GkFAvDur4UPqnqsuVWJg5FqEdNwpwiUhisIpfI6VxbEOjzqxRI1WtLp8dE3\n4sHqiF+0FS/+oEKjkfjOZQt4bFt7aOjLRNB/WHTcbHkbas6Of4x7WFhMELJzBhtFY7nx0LRZLIyq\ntXHD42IQTn6SoPNEodHCtQ+LdMsUoVUVRCCB7ecVi78uIzLNFYTFBFBtcICT1GIQEFr4evaIWISk\nwVe0IGnWXgRUgug9EH/2RDhUO9TeKayxZASRkQvX/vnkLMxqJlN4JwMV5Uvh8nvENLuTiJNOELIs\nH5Qk6afAS4iP0C7AH3WMLElSXM9HluX7gfsBVqxYccK+0KCy8DQrhWgngoPdkWMoNUpaaqJqaqtz\njNcO9XHz6pq4DfhUi+rNxgEkidiWGBOAXqth09dCdQFBqJW4Cz8BjRtFwBSiFISy+Dv6xP+H2uCq\nP4jGaeNBlfrdu4SSCI9V6E0gacmSxesTT0G0KOrJlmAe9ntNg9RaMinNjZ8KuabOEkz3nTBUdZVo\nJrDXLdpOBxWEmsmUAkF4RqBzG6y+I3RdThksue74zjUZ5l4wseM1qsWUoP2JYjFJ4Z68wQw6Exat\n+F+52ocpZQURSnumWzQV/NV1a8bN2gtC3YjI/vEzwNSEiuFOEZdxWUVvpEQ47dLUzuFEkTdLqNV4\nBCFJsPTGk3MeYZiWILUsy3+QZXm5LMsfAWzAEaBXkqQyAOUySWXW5GFQmZ3bPHBiFpPPH+BYv4N5\npZE71SrFJoqHp3d24gvIXLU8fgaQWiy3tdlKea4pJq4wUViyjLFfOFuL2LHOXif+VofTRMQgVAXR\nL9o7mApSz9BQ++R0bheX4dlOkgQZOZiSEIQ6B3soTjM/nz/A1mYrZ80uSO1cJgo1aJ+IINQiOVVB\nJGsnHY3Wd0S8QR16cypBo7TaCMQnCMmrfJ6jg7bmQgoQarBEq6TtphqDyCqG7HIRh1BqNqoKzJHZ\nduPdHkUZJ8qoUxFUEEomk2sgsYI4mcivEapmuBO0xpRjRlOJ6cpiKlYuqxHxh0eAZwF1kvoG4JmT\ncS6qgmgZSL1nUjx0Do3i9cvMjmqFUZlvpiNODGJL0yD/b+MhVszKj20AF7ytkNceXyDlAPWEYWsR\nO5ecMmGRtL8nrg8nCEOm6FLZux8OvyDaPCTzeMOhWgwqQUTv7ozZZAQEOcerhUimIA502xnxxI8/\nTApUYkg050Et7FIVhM4gSCLe2MloNG0WKb9VCSp+pxOKgiBBHYSkWEwxBJFZSJ5CEBbJrixyE7D2\nyhvg2CvC5pxoHEarDynd8RREVrF4jsOdykTAJBbTyUR+DSLQvkOcYyqpzlOM6aqDeEKSpAPAP4Db\nZFkeAn4CXCBJUiNwvvL3lGPQKRaephO0mFSLqiaGIEwMOsdwekK7sZ1tNj774PtU5Jn47U3LSYQM\nvZaSHLEQJ+vietyQZbH4qRkSs9eF/hdtDWQWiVYSAV+oN38q0BmEP63uqqOznYy5GP1JFIRC3B5f\nIGamhRp/iM5gmjSo8Rl7V/zxkNEKAoQdcew1sHfHHh+OptdFO4hkfYqmC2qrjQQKQuNTCEIftWkx\nF5LlFwSRLw8pPZImsMiVNYRSPI/H81dtpmQpriDiMtnlYrc+5hB1PKcMQaB0852Cos7jwHRZTOfI\nsrxAluUlsiy/olw3KMvyebIsz5Vl+XxZlq3j3c9kYNDhQZJEsPpE2j20BAki8kujxhE6lVqIfZ3D\nbHhgq9Lv5ayYoGw0VJspWRfX44ajV3joQYJQ7I6MXLGwhyOzSJBD9eqJZ3SoKYiG7NjZxMZs9F6R\nwhpPQagZXBCrIra32qi1ZMbvSDsZsLWKXT6yaJkdjaCCCMufX/Zp4YPv+nPi+x3phb79Yuj9qQhV\nQSQgCK3PRQBlLnM4zIWY/eI1yfEPpW4vqQim90pKNfIEodqZiRr1hSO3QigIZ2ybjWmD+j30e1IP\n7k8xZnQltc8fwObyBqektZyAimgecJJl1FGkLvjOQRhzRqS6Ng842fDAVrKMOh75/JkJA6v4vcGC\nH5VgxlUQ1uaJdxINzhJQUuhqzhZpl/E+nGocYvmG2P+NB7UNeLydXUYOmrERTPr4Lb9bB53BmRFW\nZyRB9Njdwddn0uEbEx612vQtXhwinoIomC0W/h1/CrV8jkbzG+Jy9rpJOtlJhkoQCeogtL5R3FJG\nrDowF5IxJlJHM70pFsmFQ1UNlnoI7/OUKrJTVBAgbCh7R6iK+lTYsWeVKBsSJv7aTRFmNEFYlR3p\nGcpMgBPJZGoedFFjMYdSSB+6DP75raAC2NFm46Y/bEEGHv7cmYkzkgIBePxmuOdM8IwEF8CkKa7b\nH4K7G6Dx5YmddPSwmYxcqF4Vv/lb3iyxy1pw+cQeA0KZTPG8YWM2eOxx2224xnz02j3B8Z/RgepB\nxxiWzCilM1kYbhdZV7PXib/jEURQQUSpouUbBMGrGWHROPJPEbc4iU3XJoRgkDp+ixidf5QxKc7m\nxmxB53XwlXWzyPLZJr4Lzi4Vn7PqMyd6xgIFc0TMIytJI0oVuRXCOlQzhk4FBaHRhArmJqq+pggz\nmyCUHemy6nwkKdSm+HjQEt4Kw+8VPf27d2HJMpCh13DPa8ewOsf4481nRI73jMZbP4dDz4lc89Z3\nOG9+MefNL2a2JcFtOrbBC18Xv7dvmdhJ21oAKTLF75qH4RP3xR67/r/g1jdjbYVUkJ1EQRhzwDMS\nlyDUDKal1YLAwy0mWZbpd3iwpFpINVGohFB5hig0i6sglFkQ0QQx/1KR6bXjodjbuKxw8B+w+OrY\n+RmnCpTzkhLUQej9o3jiEoTIJvvK6kIk18Dx7co/+0+48IcTvx3AWV+GL72d2qyEnEoRe1Bndpun\nKBNuolA3Z2kFMf1QM5hKczOozDcdt4IY8wXosLmoVQPUwx3Chx5oRJJlqvLN6LUSv71xebD1dlw0\nboJXfyiar+kyoGkzS6ry+MPNZ8TPB3f0waM3iZ1Xfm1q2TPhsLWIYrXwjKTMwuBkrQgYs1OT7vGg\n7ujiecPGbHDbyc3QxSEI8X4sDSqIEEE4PD7GfAEKp0pBBGc914o04EQWkyErtjeOzigyvQ49HztH\nY/ffhMd8PFbdyYI2eZqrITCKVxOPIJTPjbVJLL7HMxcjpzy19tjxoM8I7cDHg/pZ7lY6yJ4KCgLC\nCCIdg5h2qFXUliwDtZas4yaIdpuLgBzWCkNdTLwusHfy35cu4I83r0w8wQ1EDOGJW0QzrivuFd63\n2hspHvxeePwzouvjtX+GWatF9sNE4hC21uSzBCYLybzhjBwIeCnIiJ1LrQ5JUknVFmYxDSjkPl6Q\nPyXIsqhLCH/tbC2ic2Z2mVLhGifVVe3kGg/LNogg765HIh9nx0NiUEyKjfOmBUoMQkpCEGPaOJan\nqhj6Dyp/nxq74LhQ7c7u3cJSm0g67lQiSBCnQEyEGU4QqoIozDRSW2imecB5XE37WqJTXMPz5gcO\ns7a+iLPHm0XwyveE533tn0VV6ux1ItMl0SS3l78DrW/BZXcLL7usQRT82LtSP3Fby8khiKL5ooCs\nZGHs/5QvZonRE5PF1DLgpDDTQEGmgSyjLsJiGlTIvTBrEhTE0VfgjxeLSxVqfYhGEzvMRYXayTUe\niurFQJ+3fxkil/atwnpcdgqrBxg3i8kQcOPVJlEQakrzqUwQajHd4FFx3qdAzQEgKvA1etFc8RTA\njCYIq3MMrUYi16Sn1pKJw+Oj3xGnpfU4UJVHsEhO9fYhte6ejn44+BwsvQkKlIwiNQVSzXgJx57H\n4b3fwJlfDI0fjDP8PSm8bhjpOkkEUQ/fbIvffkIhiCL9WIzF1BI2AyPPrI8IUk+qgujcJi6PvRq6\nLpw882vEJC9XVOZ1MgUBogGfHIBHbwTvqFAPhixYdNWJn/NUYhyCMMpufPEUhEoQfR8ABWEuFIV8\nyKeOvQTCCfiPluStP04iZjRBDDo95JsNaDQStUrguPk4AtXNA05yTXryVT9cXVxM+anNB9j9iJjP\nHO5Lly0Ri090JkzPXnj2dpi1Bi78Qej60sUiRTVs+HtSqH3zTwZBQOK0RaWdQIFuFIfHhy+s5Xfr\noCuoyvLNhggFEbIHJ4Eg1EE1TZtD16ktSCA0sW2oJfJ2yRQEiAZ5V/5evGdP3Qr7nhT9q44nhfNk\nQiEITQKCMMlu/Lo4yQpq08H+Q+LyRGZzTzUkKdgs8pQJUKs4hT4fM5ogBhxjWBSLQt39twxOnCBa\nBp2RFdS2FqEELPPGJwhZFjnzVWdFFqBptKINdNPrIWvDZYW/3SAWpasfjAyOGszi8bqSKIjDL8JQ\ne+gcIfm4ypMBJSBZoBMLvt0tFiW310/3sDsY18kz6yNiEEF7cDIspu7dwgJTLb1Rm8hQClcQEBuo\nHk9BANRfKCaMHXhGTCY71e0lCH2uEhBEBm78ujgKQqsXr4ezH5BEJtepDNVmOkX8/lMRM5ogBh2e\n4AJTnmfCoNWk1HLD44vMD28ZcFEbXumsKohUJoy1vi180OU3x/5v9jqRj29tEgN3nviciDFc83D8\n3VnZksQW057H4K/XwZ8uFwtbMEunJvn5TTUUBZGnEZXmqs2kpriqFlO+2RCRxTTg8JBn1qOP0wV3\nQnD0Catt4SfE381vhGIGQYIIGwcZjvEUhIpzvi4GAs05L7U24NMNVUHIsQQRCMiY8BCIRxAQsmvM\nhamlm04n1ED1qWQxnWKY2QThHKMwU1gUWo3ErELzuBbTwW47K76/iUffFxaN2+una3g0pCDcw2IH\nml8jFIGzP9a7Dsf2B8GYG78ArXaduGzaDK/9SDQy+9idUHVG/PsqbxDtM9QRnyq698Czd4j2BUOt\nwu6wNon8/um2AZQYRLYUSRCqkqsNWkx6bGGV1INOz+SkuKqKa9mnRT1D02uxBYSGTJF2GE4QvjGR\npTaeggAR6L7qd3DjE6dOMDQZksQgPF4/ZjzI0X2YVKiL7akcf1CRmyaI8TCjCcLqGIuwKGotmUlT\nXb3+AF9/fDcjHh+/fvUoPn+ANqsLWQ4tZMHdZ96syPkA8eCywoFnRaDZEOcLVzhH1A68cze8+TOx\niK34TOInFGf4Oy6rl31cfgAAIABJREFUCJKa8uGmp+CiH4tK3u0PigVwuhcslSAQisEeVBDifZhV\noFpMBuzuUIxiYGRscuIPasymvAFqPyIsPbXNd7j9pmYyqUhUJJcM0/1apwpJwo8GSY6tpPa4HWgk\nObZRnwrVrjlFKoGTIq0gxsWMJQi318+Ix0eFwQXv/gZkmdqiTFoHXfgD8VNd7918jP1ddq5dUUWH\nbZQX9/UECaXWElUDkV8TRhAJ5gOoRVOJfGlJEg30bC1QvgwuvjP5kypdDEghm0m1pUa6xVSxrGJY\n+XlYcr3Y/U63vQRBi8lMpIJoHnCRb9aTaxZ+eL5yqf5/wOmZJILYJVo0ZOSKzLHhdtGN1VQQWbCV\nPyuyFiJeH6YPEQKSNm6Q2uNS5qZEt/pWoQZ8PxAKQolBpAkiIWYsQahtNk4feRM2fgv6D1FbmMmY\nX1RFR+Ngt51fv9rIZUvK+fGVi5ltyeT+N5pi23yHE0RetUilSxSHOPScWNRLk3SuPP0a4Vtf+/D4\nraGNWSLuoe6KX/1ByJaqXCGukyS49C4xYrT+wuT3dzKgM4AuA5NfvI7DYQoivEGhmiGmBqoHRjzB\nBIMTQteuUJO42eeKy+bXY8kzv0ZUyKsN7KJnQXzI4EeHFCcG4XUrBKFPRBCqxXQKZzCpKF8mvlsV\niVvuz3TMWIJQs2BytIqvbWtlRY3Y/by4L9LDV62lXJOe7318IRqNxOfOmc3ezmH+vr2DwkxDaJTn\nUKtYNEx5IhPJMjd+LYTHIQqn5pyX/ERnr4MvbB5/SpaKsgax6B14Ft76hVAn0QFwvQlu/Dus+Gxq\n9znVMOZgDAiC+NlLh1l752u832INqTKExQSiH9OYL4Dd7aPwRBWEc0B09FStucI5IdshHkHIfkES\nMDMURDyCGBUEoTGORxAfgMygrCLx3VJrj9KIwYwliAFl1Gi2VtkR2lqoK85iZU0Bf9vaRiDMZnpm\nVxf7u+x89+MLKVB2slcuq8CSZeBonyM2xTV8cUmUydT2rqh9mOyRk2VLRFbOU7eKndHHxrGlTgUY\ns9F5HXzjonmsn1dMQ1UeH11Uxg1nhvrqqBaTzTkWHBN7whaTasWpRYaSFOreGo8gIKQQP+wKQtKh\niROD8LnF7A4pXswMxHAomP7khzQmBTOWIKyKgsiUVAXRAsD1Z1bRMuji3SYx2cofkPnN5qPML83m\nksVloh33S/9Nhr2FT6+qAcJ6MKn3kx8W3LTME6oieiJZ02ZhP1WvmtwnptolhkyRDpvqaNDpREYO\nuO3cdm4dv7i2gV9dt5RfX780qOhApLmCaPk9aTUQXVEEAaEK9oQEoQSwZ4CCiBek9nuE0tNmJCjm\n+iBZTGmMixlLEOou1CwprTWUuoCLF5WRa9LzyFaRxrpxfw9N/U5uO7dOzHoYboN3fg2HnuOms2aR\nZ9azpErJZAn4RYVy+OJSVC/aLViPRZ5A0+tQtfL42mcnQ8Vy0W762j8ff/fVkw1jNnhGkh6SpyoI\n11iwHcqJK4jdoltr+CJffxGcdhnMWR95bHa5GOhyZKP42/3hVhCypEUbx2LyKzGIhARRtVK8flUr\np/L00jhJOMUrWaYOg44xDDoN+oBCEIqCyNBruWpZJQ+/10L/iId7XjtKrSWTjy1Wht44lAEjjj7y\nMw288831mPRKX/+RbtHmOMJiUjKZ+g+HmtU5B6B3L6z/9uQ/Mb0JrvvL5N/vVMKYA86mpIdkGXXo\nNBK2MAVxwkHq7l2xAUpTniDXaGg0sPRGeOsuMapydEikekaPZv2QIJHFFFAUhC5hDKIg/uuXxgcS\nM1ZBDCjTyCSfSK8M79b5qTOr8PplvvroLvZ32fnS2jloNUoOu1PprqrMsjUbdKEpctEVuKB0ZZQi\nayGalTbeatbMTIcyNCgZJEkiT6mmnpQ+TC6rUHsTmeq29CahBnf+WSiID6l6AKEg4lZSe4SC0JtP\nkfbYaUwpZixBWJ0ekQXjVVJava7g+MG64mxW1hTw1tEBynMzuGJpmFWjjih0xmnDHV2BC2JHn1cN\nXTtC1zW9Lqqn1XjBTIcSgxgPBZl6bK4xBh0eMvQazIYTmMjW+o64LJvAe1BQK4LYO/4ELtvEiuQ+\nYAhI+rgKgjHxfdFnjDMjPY0PBWYsQQw6x0RGknc0dGVYpeynlAyaW9fOiZzmplpMKlGEw9YiOqrm\nRrXqXXy1qF5Wh8c0bRaN+E7VkZMnG8pc6vGGHeWZDdhcXqXJojGk3CaKkR54/msi/lA1wfnHy28W\nqbFNr31oA9QAskaLhliCkL3CYjKYsk/2KaUxDZjRMYi64ixwjoqMC2efsIiU4NrHl5STadRx7ryo\nilCVGBwJCCKnMnYE5bpvQcdW+MdXhKIYaoVV/zL5T+qDCmMOIMOYI1hZHQ/5Zj3NA06MOs3x10D4\nxuCxTwtL66an47c4SYZ5l4hUTtfAh95i0sWxmKQxJz5Zg9E4TtFmGh8KzEgFIcsyAw6lVcOYM9Rm\nO0xBaDQSFywoQRfdLVS1llwDIuU1HEOtkSmuKrQ6+OQfRW7435XitNnrJuOpfDigksI4cYj8MAVR\ndLwB6o3fgvYtcPk9ULJg4rfXGaDhevH7h1hBBJQgdfSERck7iosMjPoZu7ecUZiRBOEc8+NRB957\nR0XmRXZZ/MH0MTcWwWkCvlCqo4roGohwZFpEuwyNXjyWZe6JPIUPF9SeR+PEIcKD1McVoD66Cd7/\nPay+HRZdeRwnqmDZzeJSHZDzIYSs0aHDT3RbMsnrwoURo25GLh0zDjNyG6AWyQVjEHpzbLfORHD0\niTiDHBB2k9qczOcRrbZzqxPftnwpfOpvol7ig9LZ82RAHRg/roLQ4/XL9I94jq9IrmefuFz7HxO/\nbTgsdfCJ+6BixYndzykMWaNDK7nxBQJow2JlWr+LUYxoNOnP70zAjCSIgfBWDV6XIIi8WdDy1vg3\ndvaL7p+DjYIsVHvK3ikuxytOiy7ASiOMIIaTHqZWU8NxpriOWkFrEHOhTxRLrjvx+ziFIUtCQUR3\nNtZ6XbildPxhpmBG6sSIVg3eURE4zq8Ri7xvLPEN/V6xyAQL3sIC1cMKQeR8QKqXTyWkGINQq6mB\n2CC1LIsZDeqP30sMRm2ijXdavY0PjRYdfrz+SILQ+UdxM8nV/2mcspiRCmJQKbQSMQhXyGJCFvMA\nCufEv6FL9GeiZCEceDqSIIIKIsWuq2mEkGIMIj8zXEFEWUwv/jtsvT/0d9F8uG1L5DEu64c6bjCZ\nkDX6uApC5x9lTJNWEDMF06IgJEn6qiRJ+yVJ2idJ0l8lScqQJKlWkqQtkiQdlSTpUUmSpqyHwaAy\nC6IwQwbkkIKAUDO2eHAoGUyWehGHiFAQShvotIKYOFLOYgopiAiLyW0X1c21a+GiH4lZF/2HwB+V\npjk6FIoZpZEcioLwRWXq6QOjeNIEMWNw0glCkqQK4A5ghSzLiwAtcB3wU+AuWZbrABtwy1Sdw2fW\n1LD56+vIkJU+TEEFQfJAtUoI2aUiF94RVk1t7xS704nm1acBBpUgxs9iUhFBEHsfF0rwvP+BVbeJ\nhnsg7MBwjNrSCiJVKArCF2UxGQKjeNMEMWMwXTEIHWCSJEkHmIFuYD3wd+X/DwFXTNWDmw06McNB\nbbOhN4lOnVpjagSRWSR+1JRXEDGInLS9dFzQaARJjBeDMAkFodVIwd8BMV+7ZDFULBN/qypBtQRV\njFo/1LULkwlZo0NLIMZiMgTceLXpTdBMwUknCFmWO4GfAW0IYhgGtgNDshws3ewApt6rUdts6M1i\nkYqeOxwNVTFkFolpVM4oBfFBaa99KsKYPW4MQqfVkJ2hoyDTEEqz7NoJPXtg+YZQ8FmdSRBDEEqQ\nOo1xIWl06CQ/viiCMAbceDXpIPVMwXRYTPnA5UAtUA5kAh+dwO2/IEnSNkmStvX3x2l3MRGoCkK1\nhcarhXD2C5VhzFYURFQMIh1/OH5k5IxrMYFIdS0MC1az/SHQmUS/KxXqVLNwghhzgc+dtphShFoo\n5/OHxSACfox48OvSBDFTkBJBSJL0pCRJl0iSNBmEcj7QLMtyvyzLXuBJYA2Qp1hOAJVAZ7wby7J8\nvyzLK2RZXlFUVBTvkNQRVBDKB14liERN45z9ol2GJIn+TWo/pjGnqKpOK4jjh9qwbxxU5JmoLlAI\n3eMQ8YeFn4i0jlQFEW4BjtqU/6UVRCqQtApBhCsIZUPl16YJYqYg1QX/N8CngEZJkn4iSdK8E3jM\nNuAsSZLMkmjHeR5wAHgN+KRyzAbgmRN4jNQQjEGEKQiPPbSYRMPZHxrGnmkBr1OQg71LXJeOQRw/\nUpgJAXD39Uv5yVWniz/2Pyka/C3fEHlQMAYRFqRWA9ZpBZEa4qW5Kq2+A/p0q++ZgpQIQpblTbIs\n3wAsA1rg/7d353FyVdeBx3+nlu5Ge2ux3CCwZELAGCwW2QHZxtgKNjjEgCGAxxPLQGCIYyDxzMTC\n9oQknj+YmXycgO0oKDYgPIRNtgxhBjEgizA2SyxiNkvCYrFGjYUkWhtSb7Wc+ePe1/W69Kq7qltV\npa57vp9Pf7rq1quq+/RaderclcdF5CkRuUJEsiM/+6DXehbXGf1vwEu+DiuArwJfEZFXgVnA92t5\n3TFJyiCgcjPT/h2lvXajTdkP7CwNcbUMYuyq6IMAmDO13S2RArDpf8HM9x68ZHem3XV6x5uYoqBv\nfRBVkbTrpB6eQbilvosZ66QORdUT5URkFvDvgT8EfgHcDXwE923/7FreVFVvAm4qK34daOxGtvFO\nanDLbYBblTUaERN34G14t//2OnlOqWyfzaIet47qMohh9m93ASJpZvTkWW7F3chQgLAMoirpLFny\nw/sgBl2A0DZrYgpFVQFCRFYDxwM/AH5fVbf5h+4TkfX1qlzd+T/4UgbhA0RSBqHq+yB8YIgCxP4d\nsWU2jqxbVVtee3Wd1MP09pT2/C43adbwDKLXmphqIan0wRnEYNQka01Moag2g7hVVdclPaCqE3dJ\ny/IMon2qGwGTFCD690AxVwoMQxnEDrfD2OR3uaYNMzbt01yfUCHv9s+oxoGe0oilcpNmuQwjYp3U\nNZF0lqwUKMQyCB08gAC0WYAIRbWd1CeKyNAwERHpFJEv1alOjVPeSQ2Vh7pGI5aiPoihALHTZRDW\n/zA+7dXNph6S63Nt4pU+8CfNPriTOtNRyhbNiMTvipjPlxY9zA/sd49ZgAhGtQHialUd2h1HVXcD\nV9enSg2U6wNk+Df/zvckB4ihWdT+G2u2w33r3b/T9UFY/8P4dFS3J8SQ6MM/GtJabtLMg4e5Wgd1\n1cRnccXYelb5PndtpN0CRCiqDRBpie0QLyJpoG6L6TVMtJJrvJOzc74blVS+0Fs0azoavQSlyXJ7\n37RVXMer1gwi6l+oGCBmQb6v1G7et8f6H2oQZRCF2PL3+X7XZ5eyABGMagPEGlyH9BIRWQLc48sm\ntmgviLjO+W470X1l8/TKm5jABYtdr8HgO5ZBjFf5rnIv/xB2bKx8fDRCafIIfRBQCiS9u6z/oQaS\nchlEIR/LIPpdE1O6/RBsuGQmhGoDxFdxE9n+2P+sBf68XpVqmGi70bhKcyEO7HRLfMc/ZCbPhu0b\n3G3rgxif9tieEC/cB6uuhLsugH3bko8frYkpChxRIOnbbQv11SCVcRlEsVDKIIo+G0u32zyIUFQ7\nUa6oqstV9RL/c5uqFupdubrL9SZnEJAQIHa4D6PY/rxMfpcb2QQ2i3q8oj6ILT+Ff74ejjzNLaXx\nwNLkXf6qaWKKH9dnmwXVIuWbmDTW1FrIDVBUob3NRuuFotq1mI4TkVUiskFEXo9+6l25uksKENOO\nglQmIUC8XRq5FInftwxifKI+iKe+7T7c/939cMF3YOuz8OiNBx/f2wNI5Q/9oQCxy81hsU7qmiR1\nUhdz/QySoT2brvQ002KqbWK6A1gO5IGPA3cB/7NelWqYXN/BY7pTaZh+9MEBYv+OgwNENGlOUjDl\n3XWrZhCiJqZ0G1z6A/dve9JnYfH18PPvwYsPDD/+wNsuOKQqfFjFM4hcLxQGLYOoQTrjxqAUc6Vh\nrprrZ4AsHRYgglFtgDhCVdcCoqpbVPUvgd+rX7UaJCmDANfMtKdsX4gDOytnEFO7qp/cZZJlj4AT\nzocLl8O800vlS25yy2m8/MPhx/f2VG5eAuiY4beFfTvWX2EZRLWiDEKLpQBRzA8wSJb2TLP2GTON\nVu2n2oBf6nuziHwZtxT3xB/KkOtLXh6jcz5sfGh4WbTUd1w0oslGMI2fCFx+98Hl6QzMOs7NVo8b\nLUCkUq5JqbfH1mEag/RQE1MpQJAfYIAs7RnLIEJR7VeBG3Bbg14PnI5btG/piM+YCKJ5EOU657sP\nlmh10cFet6x0+ZDKKIOw/of6mn5Uab2rSO+uykNcI9F6TENLfVsGUa1U1jcxxYa5an6AQc3QkbUM\nIhSjXmk/Ke4yVd2vqt2qeoWqXqyqzzSgfvWVNA8CSov2Rc1M0SS5yWUZRNQHYRlEfU07yn3IR5Pe\nwA1fHa3JaPJsyyDGKJ0wimkog7A+iGCMGiD8cNaPNKAujZc0DwIOHur6q0fd766Fw49rnwYfvgFO\nvgRTR9Es9WhjJtXRm5jABZDeHuuDGINoHgTF2BDjwiCDZOmwPohgVNsH8QsReQh4ADgQFarqj+pS\nq0YZqZMaYPcW92H03EroOgW6PjD8OBE456/rXs3gRRnavm6Y/VtuOY5ivvJKrpFJs6D3mVIG0WET\n5aoVZRDxYa5SGLBhroGpNkB0AD3AJ2JlittPemLKD7oPmaQAcUQndEx3GcSbz8GOX8L5f9vwKhov\n6uOJ+iFGmyQXmTTLZQ+9u1ymmO2oXx1bzNAoplgntRQGGFQbxRSSqgKEql5R74o0XG6UzU9m+FVd\nn7vDHXOSNSM1zVAG4QPEgWoDxGzQAux+wzqoa5U6uA8iVRhkUDrIpi1AhKLaHeXuwGUMw6jqlYe8\nRo1Svh91uc75LnvY8jM46eLSUhCm8TLtbsRYtPd3LRkEQM+r1kFdK79YH8V4E9MgBbH/ByGptonp\n4djtDuAi4DeHvjoNlLRZUFx8LsTpX2xEjcxIph1VyiCiADG5ygCx6w14z5n1q1srSmhiShcHKfjM\nwoSh2iamYdNYReQe4Kd1qVGjVJNBAMw9CY46PfkY0zjT50HPa+521RmEb1Yq5iyDqFVCBpEuDlKQ\nib8NjKneWBsTjwPeNepRh7Py/ajLzVzgfp+2dPiGQqY5hmUQb7s1m9pGmcwfn0hnfRC1SQoQmqOQ\ntgARkmr7IN5heB/EW7g9IiauoSamChnE/LPgM9+GD1zWuDqZyqYf5Ya39u8rzYEYLXDHMwzLIGoT\nBYhYJ3WmOIhmLUCEpNompqn1rkjDjdbElM7AaV9oXH3MyOIjmXp3jT4HAlx2mOmAfL8FiFolZBAZ\nzVFM2V4QIal2P4iLRGR67P4MEbmwftVqgJyf71e+3Lc5PEWzqfe+6VZorWZWtEgpkNgs6tqko5nU\nPkCo0saga9ozwai2D+ImVd0b3VHVPcBN9alSg4yWQZjDS7Tq7r7u6pbZiESBwTKI2vgMQqIA4Ucz\nacYyiJBUGyCSjpvYGyCM1kltDi9TuwBxGURvz+gruUaiQGKd1LUZamLyw1wLAwBo2gJESKoNEOtF\n5Fsicqz/+RbwXD0rVnejdVKbw0s6C1Pf7VbY7d9TQwYRBQjLIGoylEH4ref9vuBiGURQqg0Q1wGD\nwH3AvUA/8Cf1qlRDRBlExgLEhDHtKHjrZXe72gAx2fogxiTKINQ3MeX7AZCM9UGEpNpRTAeAZXWu\nS2Plet0Il5StKzNhTD8KNvpJ/dV+4HfOd/MlbCXX2vhOailrYkpZBhGUakcxPSYiM2L3O0Xk0bG8\noYgcLyLPx372icifishM/z6b/e/6tglU2izIHL6mzXOL70F1w1wBFl0JX3oG7JtvbcqamDTvAoTY\n/5mgVPv1ebYfuQSAqu5mjDOpVfUVVT1FVU/BbV/aC6zGZShrVfU4YC31zlhyvZVXcjWHp/jWrtU2\nMWXaYcbR9alPKxOhQArxTUy5QdfElMpaBhGSagNEUUSOie6IyHwSVncdgyXAa6q6BbgAWOnLVwL1\nnWcxWGGzIHP4mjaGAGHGrEB6KIMY7Hd9dmkLEEGpdqjq14Gfisi/AAJ8FLjmELz/5cA9/vZcVd3m\nb78FzE16gohcE733Mccck3RIdayJaeKJJsuBBYgGKEq6lEEM+ADRZpsuhaSqDEJV1wCLgFdwH+j/\nEegbzxuLSBvwGdw2puXvp1TIUFR1haouUtVFc+bMGXsFcr02B2KiiTKI9mnWp9AABcmQKkYBwjUx\nZdrsS1VIql2s74+AG4B5wPPAGcDTDN+CtFbnAf+mqtv9/e0i0qWq20SkC9gxjtceXa7PltmYaKa8\ny3We2pDVhihKmpQfFBD1QWQsgwhKtX0QNwAfBLao6seBU4E9Iz9lVJ+j1LwE8BCw1N9eCjw4ztcf\nWa7PMoiJJpWGqUda81KDFMmQ8k1M+UHXYGABIizV9kH0q2q/iCAi7aq6SUSOH+ubishk4BzgP8SK\nbwbuF5GrgC3ApWN9/arkrJN6QlrwUdfEZOou3geR901MWQsQQak2QHT7eRA/Bh4Tkd24D/Ex8RPv\nZpWV9eBGNTVGrg/aLIOYcC78+2bXIBhFSZPyo5jyOR8gOuxLVUiqnUl9kb/5lyKyDpgOrKlbrRoh\nd8CamIwZQVFKTUyFnJso19ZuASIkNa/Iqqr/Uo+KNJwNczVmRJoqdVIXfR9EuwWIoIS5EFEhD4VB\nyyCMGUFRsqRxGUS01EZbh/VBhCTMAJG3zYKMGY0b5lp0t32A6OiwL1UhCTNA2G5yxoxKY/MgirkB\nBjRDR9vE3ifM1CbQABFtFmTfhoypRFMZMkT7QQwwSJaOTJgfGaEK82pbBmHMqFQypCmgqpAfIEeG\nTDrMj4xQhXm1hzIIW2rDmEpcBlEgX1QoDDCIrX8VmjADxKDtR23MaDTlMohCUZHCIDnJNrtKpsHC\nDBBDTUzWB2FMRak0GYrki4oUBshbgAhOoAHCMghjRqOprGtiKhRJFQYtQAQo0ABhndTGjCqVHuqD\nSBUHyaesDyI0gQYIG+ZqzGiiDKLgA0TBAkRwAg0QlkEYM6pUhoy4DCJdHKRoASI4YQaIrg/AGV+y\nDMKYkaQypCmSLxTJqGUQIQpz3vyCs9yPMaYyP5O6t6hkiznLIAIUZgZhjBmVpDJkKFIoKhnNoen2\nZlfJNJgFCGNMsrTrpM4VimTJQdoyiNBYgDDGJJJ0ZmgUU1YHIWMBIjQWIIwxyVJRBqG0kQdrYgqO\nBQhjTCJJZ8hKgb6BPG3kIGu7yYXGAoQxJpGk3SDHA329ZKSIWB9EcCxAGGMSScqtvdTf+467bxlE\ncCxAGGMSRRlEzgeIVNb6IEJjAcIYkyiVcRnEYN9+ANK2NE1wLEAYYxJJymcQ/S6DSFsGERwLEMaY\nRJJ2GUShzweINuuDCI0FCGNMoqiJqThwAIBMm2UQobEAYYxJlPKd1MVB3wfRZn0QobEAYYxJlIrm\nPQy6DKKt3ZqYQtOUACEiM0RklYhsEpGNInKmiMwUkcdEZLP/3dmMuhljnFTGZRCpnAsQ2XbLIELT\nrAziFmCNqp4ALAQ2AsuAtap6HLDW3zfGNEnKd1KL36K3zTqpg9PwACEi04GzgO8DqOqgqu4BLgBW\n+sNWAhc2um7GmJKokzqVd1v0ZjtsB8bQNCODWADsBO4QkV+IyPdEZDIwV1W3+WPeAuYmPVlErhGR\n9SKyfufOnQ2qsjHhSfsMIltwGUS7NTEFpxkBIgOcBixX1VOBA5Q1J6mqApr0ZFVdoaqLVHXRnDlz\n6l5ZY0KVyroA0VZwGYRNlAtPMwJEN9Ctqs/6+6twAWO7iHQB+N87mlA3Y4wXZRCTpN8VZCxAhKbh\nAUJV3wK2isjxvmgJsAF4CFjqy5YCDza6bsaYkmgexCQGXIEFiOBkmvS+1wF3i0gb8DpwBS5Y3S8i\nVwFbgEubVDdjDAzt/zA5yiBsR7ngNCVAqOrzwKKEh5Y0ui7GmApSaQAmYU1MobKZ1MaYZFEfBAMU\nSA0FDBMOCxDGmGR+ue9JMkBObLvREFmAMMYkiwIE/eQk2+TKmGawAGGMSZYqjWIqWAYRJAsQxphk\nPkBkpUAhZRlEiCxAGGOSpUtBwTKIMFmAMMYkS5VGwRdSFiBCZAHCGJMsFiCKaQsQIbIAYYxJFgsQ\nagEiSM1aaqNucrkc3d3d9Pf3N7sqh0xHRwfz5s0jm7WOQtNA8QCRslnUIWq5ANHd3c3UqVOZP38+\nItLs6oybqtLT00N3dzcLFixodnVMSOIBwpbZCFLLNTH19/cza9aslggOACLCrFmzWiojMhNEKkUx\n+oiwJqYgtVyAAFomOERa7XzMxJHHr79kGUSQWjJAGGMOjaK4ACEWIIJkAcIYU1HRZxCS7WhyTUwz\nWIAwxlRUENdRnbIMIkgtN4op7q/++Zds+M2+Q/qaJx45jZt+//2jHnfhhReydetW+vv7ueGGG7jm\nmmuYMmUK+/fvB2DVqlU8/PDD3HnnnWzfvp1rr72W119/HYDly5ezePHiQ1pvY8YiamJKZS1AhKil\nA0Qz3X777cycOZO+vj4++MEPcvHFF1c89vrrr+djH/sYq1evplAoDAURY5ptKIOwABGklg4Q1XzT\nr5dbb72V1atXA7B161Y2b95c8dif/OQn3HXXXQCk02mmT5/ekDoaM5oog0i3HdHkmphmaOkA0SxP\nPPEEjz/+OE8//TSTJk3i7LPPpr+/f9hwVZvXYCYC9QEi02ad1CGyTuo62Lt3L52dnUyaNIlNmzbx\nzDPPADB37lw2btxIsVgcyi4AlixZwvLlywEoFArs3bu3KfU2plzRNzFlbBRTkCxA1MG5555LPp/n\nfe97H8uWLeOrOTHdAAALUElEQVSMM84A4Oabb+b8889n8eLFdHV1DR1/yy23sG7dOk4++WROP/10\nNmzY0KyqGzNM1MSUabcAESJrYqqD9vZ2HnnkkcTHLrnkkoPK5s6dy4MPPljvahlTsyiDyFofRJAs\ngzDGVKQpG8UUMgsQxpiKpk32mUPaAkSILEAYYyqaNskHiIyt5hoiCxDGmMpS0Wqu1kkdIgsQxpjK\nUn4XQ2tiCpIFCGNMZdGuctbEFCQLEMaYytI+QFgGEaSmzIMQkV8D7wAFIK+qi0RkJnAfMB/4NXCp\nqu5uRv2MMd5QBmEBIkTNnCj3cVV9O3Z/GbBWVW8WkWX+/lfH9Q6PLIO3XhrXSxzk3SfDeTePeljS\nct9r1qzha1/7GoVCgdmzZ7N27Vr279/Pddddx/r16xERbrrpphFXfjWmoSxABO1wmkl9AXC2v70S\neILxBogmKl/u+4ILLuDqq6/mySefZMGCBezatQuAb37zm0yfPp2XXnKBbPduS5rMYcQ6qYPWrACh\nwP8REQVuU9UVwFxV3eYffwuYm/REEbkGuAbgmGOOGfldqvimXy/ly32vWLGCs846iwULFgAwc+ZM\nAB5//HHuvffeoed1dnY2vrLGVDI0zNU6qUPUrE7qj6jqacB5wJ+IyFnxB1VVcUHkIKq6QlUXqeqi\nOXPmNKCqtYsv9/3CCy9w6qmncsoppzS7WsbULm0ZRMiaEiBU9U3/ewewGvgQsF1EugD87x3NqNuh\nkLTcd39/P08++SRvvPEGwFAT0znnnMN3v/vdoedaE5M5rKQygJQChQlKwwOEiEwWkanRbeCTwMvA\nQ8BSf9hSYMIub5q03PecOXNYsWIFn/3sZ1m4cCGXXXYZAN/4xjfYvXs3J510EgsXLmTdunVNrr0x\nMams66CObXZlwtGMPoi5wGq/u1oG+CdVXSMiPwfuF5GrgC3ApU2o2yEx0nLf55133rD7U6ZMYeXK\nlY2oljG1+8Cl0PmeZtfCNEnDA4Sqvg4sTCjvAZY0uj7GmBEceYr7MUGymdTGGGMStWSAcIOgWker\nnY8xZmJouQDR0dFBT09Py3yoqio9PT10dNhyy8aYxjqcZlIfEvPmzaO7u5udO3c2uyqHTEdHB/Pm\nzWt2NYwxgWm5AJHNZodmKxtjjBm7lmtiMsYYc2hYgDDGGJPIAoQxxphEMpFH+4jITtys62rNBt4e\n9ajWE+J5h3jOEOZ5h3jOML7zfo+qjrra6YQOELUSkfWquqjZ9Wi0EM87xHOGMM87xHOGxpy3NTEZ\nY4xJZAHCGGNMotACxIpmV6BJQjzvEM8ZwjzvEM8ZGnDeQfVBGGOMqV5oGYQxxpgqWYAwxhiTKJgA\nISLnisgrIvKqiCxrdn1qJSJHi8g6EdkgIr8UkRt8+UwReUxENvvfnb5cRORWf74vishpsdda6o/f\nLCJLY+Wni8hL/jm3ihwe+0yKSFpEfiEiD/v7C0TkWV/P+0SkzZe3+/uv+sfnx17jRl/+ioh8KlZ+\nWP5diMgMEVklIptEZKOInNnq11pE/sz/bb8sIveISEcrXmsRuV1EdojIy7Gyul/bSu8xIlVt+R8g\nDbwGvBdoA14ATmx2vWo8hy7gNH97KvAr4ETgvwPLfPky4L/5258GHgEEOAN41pfPBF73vzv97U7/\n2L/6Y8U/97xmn7ev11eAfwIe9vfvBy73t/8B+GN/+0vAP/jblwP3+dsn+mveDizwfwvpw/nvAlgJ\n/JG/3QbMaOVrDRwFvAEcEbvGX2zFaw2cBZwGvBwrq/u1rfQeI9a12f8RGnRBzgQejd2/Ebix2fUa\n5zk9CJwDvAJ0+bIu4BV/+zbgc7HjX/GPfw64LVZ+my/rAjbFyocd18TznAesBT4BPOz/6N8GMuXX\nFngUONPfzvjjpPx6R8cdrn8XwHT/YSll5S17rXEBYqv/wMv4a/2pVr3WwHyGB4i6X9tK7zHSTyhN\nTNEfX6Tbl01IPp0+FXgWmKuq2/xDbwFz/e1K5zxSeXdCebP9HfDnQNHfnwXsUdW8vx+v59C5+cf3\n+uNr/bdotgXATuAO37T2PRGZTAtfa1V9E/gb4P8B23DX7jla/1pHGnFtK71HRaEEiJYhIlOAHwJ/\nqqr74o+p+2rQMuOWReR8YIeqPtfsujRYBtcEsVxVTwUO4JoEhrTgte4ELsAFxyOBycC5Ta1UkzTi\n2lb7HqEEiDeBo2P35/myCUVEsrjgcLeq/sgXbxeRLv94F7DDl1c655HK5yWUN9OHgc+IyK+Be3HN\nTLcAM0Qk2uwqXs+hc/OPTwd6qP3fotm6gW5VfdbfX4ULGK18rX8XeENVd6pqDvgR7vq3+rWONOLa\nVnqPikIJED8HjvMjItpwnVoPNblONfEjEb4PbFTVb8UeegiIRjAsxfVNROVf8KMgzgD2+vTyUeCT\nItLpv7V9Etc2uw3YJyJn+Pf6Quy1mkJVb1TVeao6H3fNfqKqnwfWAZf4w8rPOfq3uMQfr778cj/y\nZQFwHK4j77D8u1DVt4CtInK8L1oCbKCFrzWuaekMEZnk6xSdc0tf65hGXNtK71FZszppmtAp9Gnc\nyJ/XgK83uz5jqP9HcCnhi8Dz/ufTuHbXtcBm4HFgpj9egO/6830JWBR7rSuBV/3PFbHyRcDL/jnf\noayTtMnnfzalUUzvxf2nfxV4AGj35R3+/qv+8ffGnv91f16vEBuxc7j+XQCnAOv99f4xbqRKS19r\n4K+ATb5eP8CNRGq5aw3cg+tnyeGyxasacW0rvcdIP7bUhjHGmEShNDEZY4ypkQUIY4wxiSxAGGOM\nSWQBwhhjTCILEMYYYxJZgDAtS0SeGuPzLhSREw91fcZDRLqktJrtF0XkOwnHfFlErmx87UyrsgBh\nWpaqLh7jUy/ErQp6OPkK8I+jHHM7cF0D6mICYQHCtCwR2e9/ny0iT0hpf4W7Y2vk3yxuj40XReRv\nRGQx8Bngf4jI8yJyrIhcLSI/F5EXROSHIjLJP/dOv97+UyLyuohcEnvvr/o1+V8QkZt92bEiskZE\nnhOR/ysiJ/jyPxC3B8ILIvJkhdO5GFiTcI6/JyJPi8hsVe0Ffi0iHzqE/4wmYJnRDzGmJZwKvB/4\nDfAz4MMishG4CDhBVVVEZqjqHhF5CDdrexWAiOxR1X/0t/8rbubrt/3rduFmuZ+AW8pglYich1t4\n7ndUtVdEZvpjVwDXqupmEfkd4O9x60v9BfApVX1TRGaUV9wvGbFbVQfKyi/CZRafVtXdvng98FHc\n7GJjxsUChAnFv6pqN4CIPI9bj/8ZoB/4vm/ff7jCc0/ygWEGMAW3Dk7kx6paBDaISLR88u8Cd/hv\n9KjqLnGr8C4GHpDS5m3t/vfPgDtF5H7cInXlunDLf8d9Arekwid1+Kq+O3DByphxsyYmE4r4t+8C\nbhOaPPAh3Gqp55PQhOPdCXxZVU/GrRfUUeF1R9q2M4Xb2+CU2M/7AFT1WuAbuNU5nxORWWXP7St7\nT3Dr7EwFfrusvMMfb8y4WYAwwfLf6qer6v8G/gxY6B96B/fhG5kKbBO33Prnq3jpx4ArYn0VM/23\n/DdE5A98mYjIQn/7WFV9VlX/ApcpHF32er/CZTxxW3D9EneJyPtj5b+NW6jNmHGzAGFCNhV4WERe\nBH6Ka88Ht/fEfxa3m9uxwH/B7d73M9xqoyNS1TW4/oj1vjnrP/mHPg9cJSIvAL/E9VOA6xB/Sdwm\n9k/h9kuOv94B4DUR+a2y8k3+NR/w9QS3h8Jj1f4DGDMSW83VmAnAd0ifrqrfGOGYU4GvqOofNq5m\nppVZJ7UxE4Cqrk7omyg3G5ftGHNIWAZhjDEmkfVBGGOMSWQBwhhjTCILEMYYYxJZgDDGGJPIAoQx\nxphE/x/arDnZ7CF9IgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UopND8iZ0G4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from skmultiflow.trees.hoeffding_tree import HoeffdingTree\n",
        "\n",
        "\n",
        "class REDI:\n",
        "\n",
        "    def __init__(self, data_stream_file, target, data_block_size=500, num_of_dynamic_classifiers=10,\n",
        "                 selection_ratio=0.25):\n",
        "        df = pd.read_csv(data_stream_file)\n",
        "        print(\"Number of instances is: \", len(df))\n",
        "        self.real_classes = np.array(df[target].unique())\n",
        "        print(self.real_classes)\n",
        "        self.classes = np.arange(len(self.real_classes))\n",
        "        print(\"Number of classes is: \", len(self.real_classes))\n",
        "        self.classes_mask = {}\n",
        "        for i in range(len(self.classes)):\n",
        "            self.classes_mask[self.real_classes[i]] = i\n",
        "        df[target] = df.apply(lambda x: self.classes_mask[x[target]], axis=1)\n",
        "        self.target = target\n",
        "        self.df = df\n",
        "        # params\n",
        "        df = pd.read_csv(data_stream_file)\n",
        "        self.num_of_classes = len(self.classes)\n",
        "        self.data_block_size = data_block_size\n",
        "        self.num_of_dynamic_classifiers = num_of_dynamic_classifiers\n",
        "        self.selection_ratio = selection_ratio\n",
        "\n",
        "        # extra initializing\n",
        "        self.dynamic_classifiers_weights = np.ones(num_of_dynamic_classifiers) / float(num_of_dynamic_classifiers)\n",
        "        self.static_classifier_weight = 0.5\n",
        "        self.dynamic_classifiers = []\n",
        "        for i in range(num_of_dynamic_classifiers):\n",
        "            self.dynamic_classifiers.append(None)\n",
        "        self.dcir_values = {}\n",
        "        for classe in self.classes:\n",
        "            self.dcir_values[classe] = 0\n",
        "        self.dynamic_classifiers_dcir = []\n",
        "        for i in range(num_of_dynamic_classifiers):\n",
        "            dcir_classifier_values = {}\n",
        "            for classe in self.classes:\n",
        "                dcir_classifier_values[classe] = 0\n",
        "            self.dynamic_classifiers_dcir.append(dcir_classifier_values)\n",
        "        self.static_classifier = None\n",
        "\n",
        "        # Procedure initializing\n",
        "        self.dc_indicator = 0\n",
        "        self.cc_array = [None] * data_block_size\n",
        "        self.resampling_buffer = {}\n",
        "        for classe in self.classes:\n",
        "            self.resampling_buffer[classe] = pd.DataFrame(columns=self.df.columns)\n",
        "\n",
        "        # evaluation paramters\n",
        "        self.test_batch_size = 100\n",
        "        self.test_point = 1000\n",
        "        self.accuracies = []\n",
        "\n",
        "    def create_new_base_classifier(self):\n",
        "        r_n = self.cc_array[-int(self.selection_ratio * self.data_block_size):]\n",
        "        h_n = {}\n",
        "        h_d = {}\n",
        "        buffer_data = {}\n",
        "        x_train = []\n",
        "        y_train = []\n",
        "        for classe in self.classes:\n",
        "            h_n[classe] = 0\n",
        "            h_d[classe] = 0\n",
        "            buffer_data[classe] = []\n",
        "        for i in range(len(r_n)):\n",
        "            x_i = r_n[i]\n",
        "            self.reinforcement_weight_adjustment(x_i)\n",
        "            h_n[x_i[self.target]] += 1\n",
        "            h_d[x_i[self.target]] += 1\n",
        "            buffer_data[x_i[self.target]].append(x_i)\n",
        "        classifier = HoeffdingTree()\n",
        "        balanced_size = int(self.selection_ratio * self.data_block_size / self.num_of_classes)\n",
        "        for classe in self.classes:\n",
        "            if h_n[classe] < balanced_size:\n",
        "                extra_length = balanced_size - h_n[classe]\n",
        "                if len(self.resampling_buffer[classe]) < extra_length:\n",
        "                    extra_data = self.resampling_buffer[classe]\n",
        "                else:\n",
        "                    extra_data = self.resampling_buffer[classe][-extra_length:]\n",
        "                h_d[classe] += len(extra_data)\n",
        "                # print(\"extra data is\",extra_data)\n",
        "                for idx, row in extra_data.iterrows():\n",
        "                    numpy_row = row.to_numpy()\n",
        "                    x = numpy_row[:-1]\n",
        "                    y = numpy_row[-1]\n",
        "                    x_train.append(x)\n",
        "                    y_train.append(y)\n",
        "        for row in r_n:\n",
        "            numpy_row = row.to_numpy()\n",
        "            x = numpy_row[:-1]\n",
        "            y = numpy_row[-1]\n",
        "            x_train.append(x)\n",
        "            y_train.append(y)\n",
        "        classifier.partial_fit(x_train, y_train, self.classes)\n",
        "        dynamic_classifiers_dcir = {}\n",
        "        for classe in self.classes:\n",
        "            dynamic_classifiers_dcir[classe] = h_d[classe]\n",
        "        for classe in self.classes:\n",
        "            tmp_df = pd.DataFrame(buffer_data[classe])\n",
        "            self.resampling_buffer[classe] = self.resampling_buffer[classe].append(tmp_df)\n",
        "            self.resampling_buffer[classe] = self.resampling_buffer[classe][-balanced_size:]\n",
        "        return classifier, dynamic_classifiers_dcir\n",
        "\n",
        "    def dcir(self):\n",
        "        number_of_current_classifiers = min(self.num_of_dynamic_classifiers, self.dc_indicator)\n",
        "        dcir = {}\n",
        "        tot = 0\n",
        "        for classe in self.classes:\n",
        "            val = 0\n",
        "            for i in range(number_of_current_classifiers):\n",
        "                val += self.dynamic_classifiers_dcir[i][classe] * self.dynamic_classifiers_weights[i]\n",
        "            dcir[classe] = val\n",
        "            tot += val\n",
        "        for classe in self.classes:\n",
        "            dcir[classe] /= tot\n",
        "        self.dcir_values = dcir\n",
        "\n",
        "    def shift_classifiers(self, dynamic_classifier, dcir_d_v):\n",
        "        for i in range(self.num_of_dynamic_classifiers - 1):\n",
        "            self.dynamic_classifiers[i] = self.dynamic_classifiers[i + 1]\n",
        "            self.dynamic_classifiers_dcir[i] = self.dynamic_classifiers_dcir[i + 1]\n",
        "            self.dynamic_classifiers_weights[i] = self.dynamic_classifiers_weights[i + 1]\n",
        "        classifier_index = min(self.num_of_dynamic_classifiers, self.dc_indicator) - 1\n",
        "        self.dynamic_classifiers_weights[classifier_index] = 1 / float(self.num_of_dynamic_classifiers)\n",
        "        self.dynamic_classifiers_dcir[classifier_index] = dcir_d_v\n",
        "        self.dynamic_classifiers[classifier_index] = dynamic_classifier\n",
        "\n",
        "    def train_on_instance(self, x_new, cc_current_position):\n",
        "        x_i = self.cc_array[cc_current_position]\n",
        "        self.reinforcement_weight_adjustment(x_i)\n",
        "        numpy_row = x_i.to_numpy()\n",
        "        x = [numpy_row[:-1]]\n",
        "        y = [numpy_row[-1]]\n",
        "        self.static_classifier.partial_fit(x, y, self.classes)\n",
        "        for i in range(self.num_of_dynamic_classifiers):\n",
        "            if self.dynamic_classifiers[i] is not None:\n",
        "                self.dynamic_classifiers[i].partial_fit(x, y, self.classes)\n",
        "                self.dynamic_classifiers_dcir[i][y[0]] += 1\n",
        "        self.cc_array[cc_current_position] = x_new\n",
        "\n",
        "    def update_classifiers_weights(self):\n",
        "        number_of_current_classifiers = min(self.num_of_dynamic_classifiers, self.dc_indicator)\n",
        "        for i in range(number_of_current_classifiers):\n",
        "            self.dynamic_classifiers_weights[i] *= (\n",
        "                    1 - 1 / float(min(self.num_of_dynamic_classifiers, self.dc_indicator)))\n",
        "\n",
        "    def reinforcement_weight_adjustment(self, x_i):\n",
        "        numpy_row = x_i.to_numpy()\n",
        "        x = np.array([numpy_row[:-1]])\n",
        "        y = numpy_row[-1]\n",
        "        # print(\"train on instance\", x.shape)\n",
        "        flag = True\n",
        "        for classe in self.classes:\n",
        "            flag = flag and self.dcir_values[classe] == 0\n",
        "        if flag:\n",
        "            return\n",
        "        if self.dcir_values[y] < 1 / float(self.num_of_classes):\n",
        "            for i in range(self.num_of_dynamic_classifiers):\n",
        "                if self.dynamic_classifiers[i] is not None:\n",
        "                    if self.dynamic_classifiers[i].predict(x)[0] == y:\n",
        "                        self.dynamic_classifiers_weights[i] *= (\n",
        "                                1 + 1 / float(self.num_of_dynamic_classifiers))\n",
        "                    else:\n",
        "                        self.dynamic_classifiers_weights[i] *= (\n",
        "                                1 - 1 / float(self.num_of_dynamic_classifiers))\n",
        "            if self.static_classifier is not None:\n",
        "                if self.static_classifier.predict(x)[0] == y:\n",
        "                    self.static_classifier_weight *= (\n",
        "                            1 + 1 / float(self.num_of_dynamic_classifiers))\n",
        "                else:\n",
        "                    self.static_classifier_weight *= (\n",
        "                            1 - 1 / float(self.num_of_dynamic_classifiers))\n",
        "\n",
        "    def normalize_weights(self):\n",
        "        classifiers_number = min(self.num_of_dynamic_classifiers, self.dc_indicator)\n",
        "        total_weight = self.static_classifier_weight\n",
        "        for i in range(classifiers_number):\n",
        "            total_weight += self.dynamic_classifiers_weights[i]\n",
        "        self.static_classifier_weight = self.static_classifier_weight / float(total_weight)\n",
        "        for i in range(classifiers_number):\n",
        "            self.dynamic_classifiers_weights[i] = self.dynamic_classifiers_weights[i] / float(total_weight)\n",
        "\n",
        "    def learning_procedure(self):\n",
        "        # initializing\n",
        "        processes_counter = 0\n",
        "        # cc_current_position = 0\n",
        "        # print(len(self.df))\n",
        "        # process\n",
        "        for index, row in self.df.iterrows():\n",
        "            x_new = row\n",
        "            processes_counter += 1\n",
        "            if processes_counter > self.data_block_size and processes_counter % self.test_point == 1:\n",
        "                self.normalize_weights()\n",
        "                test_set = self.df[processes_counter:processes_counter + self.test_batch_size]\n",
        "                self.evaluate_batch(test_set)\n",
        "            if processes_counter < self.data_block_size:\n",
        "                self.cc_array[processes_counter - 1] = x_new\n",
        "            elif processes_counter == self.data_block_size:\n",
        "                self.cc_array[processes_counter - 1] = x_new\n",
        "                self.static_classifier, _ = self.create_new_base_classifier()\n",
        "                self.dc_indicator = 1\n",
        "                self.dynamic_classifiers[self.dc_indicator - 1] = self.static_classifier\n",
        "            else:\n",
        "                cc_current_position = (processes_counter - 1) % self.data_block_size\n",
        "                self.train_on_instance(x_new, cc_current_position)\n",
        "                cc_current_position = (cc_current_position + 1) % self.data_block_size\n",
        "                if cc_current_position == 0:\n",
        "                    self.dc_indicator += 1\n",
        "                    dynamic_classifier, dcir_d_v = self.create_new_base_classifier()\n",
        "                    if self.dc_indicator <= self.num_of_dynamic_classifiers:\n",
        "                        self.dynamic_classifiers[self.dc_indicator - 1] = dynamic_classifier\n",
        "                        self.dynamic_classifiers_dcir[self.dc_indicator - 1] = dcir_d_v\n",
        "                    else:\n",
        "                        self.shift_classifiers(dynamic_classifier, dcir_d_v)\n",
        "                    self.update_classifiers_weights()\n",
        "                    self.dcir()\n",
        "        for i in range(self.data_block_size):\n",
        "            x_new = self.cc_array[i]\n",
        "            self.train_on_instance(x_new, i)\n",
        "\n",
        "    def predict(self, test_set):\n",
        "        # print(self.static_classifier_weight)\n",
        "        test_set = test_set.drop(columns=self.target)\n",
        "        test_set_array = test_set.to_numpy()\n",
        "        number_of_current_classifiers = min(self.num_of_dynamic_classifiers, self.dc_indicator)\n",
        "        predict_prop = self.static_classifier.predict_proba(test_set_array) * self.static_classifier_weight\n",
        "        for i in range(number_of_current_classifiers):\n",
        "            predict_prop += self.dynamic_classifiers[i].predict_proba(test_set_array) * \\\n",
        "                            self.dynamic_classifiers_weights[i]\n",
        "        # print(predict_prop)\n",
        "        res = np.argmax(predict_prop, axis=1)\n",
        "        # print(max_props_indices)\n",
        "        # res = self.classes[max_props_indices]\n",
        "        # res = self.classes_mask[res]\n",
        "        return res\n",
        "\n",
        "    def evaluate_batch(self, test_set):\n",
        "        res = self.predict(test_set)\n",
        "        # print(res)\n",
        "        real_val = test_set[self.target].to_numpy()\n",
        "        # print(real_val)\n",
        "        accuracy = ((res == real_val) * 1).sum()\n",
        "        self.accuracies.append(accuracy)\n",
        "        print(\"accuracy for test number\", len(self.accuracies), \" is:\", accuracy)\n",
        "\n",
        "\n",
        "data_stream_file, target = \"covtype.csv\", 'Cover_Type'\n",
        "# data_stream_file, target = 'covtype_mini.csv', 'Cover_Type'\n",
        "classifier = REDI(data_stream_file, target)\n",
        "classifier.learning_procedure()\n",
        "from matplotlib import pyplot as plt\n",
        "# plt.plot(classifier.accuracies)\n",
        "inds = np.arange(1000,581012,1000)\n",
        "\n",
        "plt.plot(inds, classifier.accuracies)\n",
        "plt.xlabel(\"instances (k)\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}