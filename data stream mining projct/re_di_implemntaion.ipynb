{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "re-di implemntaion",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z5JWWd5Lunt",
        "colab_type": "code",
        "outputId": "a4638a89-4bdc-4a57-e4f8-fd009532864a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "!pip install -U scikit-multiflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-multiflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/d0/d73be8c424e116862f26cf4e0f99c41e4f0982519aa7bb923c715f05c166/scikit_multiflow-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (16.3MB)\n",
            "\u001b[K     |████████████████████████████████| 16.3MB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-multiflow) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-multiflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-multiflow) (1.3.2)\n",
            "Requirement already satisfied, skipping upgrade: sortedcontainers>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from scikit-multiflow) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from scikit-multiflow) (0.25.3)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from scikit-multiflow) (0.21.3)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (2.4.5)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.0->scikit-multiflow) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->scikit-multiflow) (0.14.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.0.0->scikit-multiflow) (41.6.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=2.0.0->scikit-multiflow) (1.12.0)\n",
            "Installing collected packages: scikit-multiflow\n",
            "Successfully installed scikit-multiflow-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfUuVg-JOiif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFcQaxVdz8th",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from skmultiflow.data import AGRAWALGenerator\n",
        "from skmultiflow.data import HyperplaneGenerator\n",
        "from skmultiflow.trees.hoeffding_tree import HoeffdingTree\n",
        "\n",
        "\n",
        "# import pandas as pd\n",
        "\n",
        "\n",
        "class REDI:\n",
        "\n",
        "    def __init__(self, stream, number_of_targets, data_block_size=500, num_of_dynamic_classifiers=10,\n",
        "                 selection_ratio=0.25, stream_length=10000):\n",
        "        self.classes = np.arange(number_of_targets)\n",
        "        print(self.classes)\n",
        "\n",
        "        # params\n",
        "        self.num_of_classes = number_of_targets\n",
        "        self.data_block_size = data_block_size\n",
        "        self.num_of_dynamic_classifiers = num_of_dynamic_classifiers\n",
        "        self.selection_ratio = selection_ratio\n",
        "        self.stream_length = stream_length\n",
        "        self.stream = stream\n",
        "\n",
        "        # extra initializing\n",
        "        self.dynamic_classifiers_weights = np.ones(num_of_dynamic_classifiers) / float(num_of_dynamic_classifiers)\n",
        "        self.static_classifier_weight = 0.5\n",
        "        self.dynamic_classifiers = []\n",
        "        for i in range(num_of_dynamic_classifiers):\n",
        "            self.dynamic_classifiers.append(None)\n",
        "        self.dcir_values = {}\n",
        "        for classe in self.classes:\n",
        "            self.dcir_values[classe] = 0\n",
        "        self.dynamic_classifiers_dcir = []\n",
        "        for i in range(num_of_dynamic_classifiers):\n",
        "            dcir_classifier_values = {}\n",
        "            for classe in self.classes:\n",
        "                dcir_classifier_values[classe] = 0\n",
        "            self.dynamic_classifiers_dcir.append(dcir_classifier_values)\n",
        "        self.static_classifier = None\n",
        "\n",
        "        # Procedure initializing\n",
        "        self.dc_indicator = 0\n",
        "        self.cc_array = [None] * data_block_size\n",
        "        self.resampling_buffer = {}\n",
        "        for classe in self.classes:\n",
        "            self.resampling_buffer[classe] = []\n",
        "\n",
        "        # evaluation paramters\n",
        "        self.test_batch_size = 100\n",
        "        self.test_point = 1000\n",
        "        self.accuracies = []\n",
        "        self.aucs = []\n",
        "\n",
        "    def create_new_base_classifier(self):\n",
        "        r_n = self.cc_array[-int(self.selection_ratio * self.data_block_size):]\n",
        "        h_n = {}\n",
        "        h_d = {}\n",
        "        buffer_data = {}\n",
        "        for classe in self.classes:\n",
        "            buffer_data[classe] = []\n",
        "        x_train = []\n",
        "        y_train = []\n",
        "        for classe in self.classes:\n",
        "            h_n[classe] = 0\n",
        "            h_d[classe] = 0\n",
        "            buffer_data[classe] = []\n",
        "        for i in range(len(r_n)):\n",
        "            x_i = r_n[i]\n",
        "            self.reinforcement_weight_adjustment(x_i)\n",
        "            h_n[x_i[1][0]] += 1\n",
        "            h_d[x_i[1][0]] += 1\n",
        "            buffer_data[x_i[1][0]].append(x_i)\n",
        "        classifier = HoeffdingTree()\n",
        "        balanced_size = int(self.selection_ratio * self.data_block_size / self.num_of_classes)\n",
        "        for classe in self.classes:\n",
        "            if h_n[classe] < balanced_size:\n",
        "                extra_length = balanced_size - h_n[classe]\n",
        "                if len(self.resampling_buffer[classe]) < extra_length:\n",
        "                    extra_data = self.resampling_buffer[classe]\n",
        "                else:\n",
        "                    extra_data = self.resampling_buffer[classe][-extra_length:]\n",
        "                h_d[classe] += len(extra_data)\n",
        "                # print(\"extra data is\",extra_data)\n",
        "                for row in extra_data:\n",
        "                    x = row[0][0]\n",
        "                    y = row[1][0]\n",
        "                    x_train.append(x)\n",
        "                    y_train.append(y)\n",
        "        for row in r_n:\n",
        "            x = row[0][0]\n",
        "            y = row[1][0]\n",
        "            x_train.append(x)\n",
        "            y_train.append(y)\n",
        "        X_train = np.array(x_train)\n",
        "        Y_train = np.array(y_train)\n",
        "        # print(\"x_train shape is \", X_train.shape)\n",
        "        # print(\"y train shape is \", Y_train.shape)\n",
        "        # print(\"__________________\")\n",
        "        classifier.partial_fit(X_train, Y_train, self.classes)\n",
        "        dynamic_classifiers_dcir = {}\n",
        "        for classe in self.classes:\n",
        "            dynamic_classifiers_dcir[classe] = h_d[classe]\n",
        "        for classe in self.classes:\n",
        "            self.resampling_buffer[classe].extend(buffer_data[classe])\n",
        "            self.resampling_buffer[classe] = self.resampling_buffer[classe][-balanced_size:]\n",
        "        return classifier, dynamic_classifiers_dcir\n",
        "\n",
        "    def dcir(self):\n",
        "        number_of_current_classifiers = min(self.num_of_dynamic_classifiers, self.dc_indicator)\n",
        "        dcir = {}\n",
        "        tot = 0\n",
        "        for classe in self.classes:\n",
        "            val = 0\n",
        "            for i in range(number_of_current_classifiers):\n",
        "                val += self.dynamic_classifiers_dcir[i][classe] * self.dynamic_classifiers_weights[i]\n",
        "            dcir[classe] = val\n",
        "            tot += val\n",
        "        for classe in self.classes:\n",
        "            dcir[classe] /= tot\n",
        "        self.dcir_values = dcir\n",
        "\n",
        "    def shift_classifiers(self, dynamic_classifier, dcir_d_v):\n",
        "        for i in range(self.num_of_dynamic_classifiers - 1):\n",
        "            self.dynamic_classifiers[i] = self.dynamic_classifiers[i + 1]\n",
        "            self.dynamic_classifiers_dcir[i] = self.dynamic_classifiers_dcir[i + 1]\n",
        "            self.dynamic_classifiers_weights[i] = self.dynamic_classifiers_weights[i + 1]\n",
        "        classifier_index = min(self.num_of_dynamic_classifiers, self.dc_indicator) - 1\n",
        "        self.dynamic_classifiers_weights[classifier_index] = 1 / float(self.num_of_dynamic_classifiers)\n",
        "        self.dynamic_classifiers_dcir[classifier_index] = dcir_d_v\n",
        "        self.dynamic_classifiers[classifier_index] = dynamic_classifier\n",
        "\n",
        "    def train_on_instance(self, x_new, cc_current_position):\n",
        "        x_i = self.cc_array[cc_current_position]\n",
        "        self.reinforcement_weight_adjustment(x_i)\n",
        "        x = x_i[0]\n",
        "        y = x_i[1]\n",
        "        self.static_classifier.partial_fit(x, y, self.classes)\n",
        "        for i in range(self.num_of_dynamic_classifiers):\n",
        "            if self.dynamic_classifiers[i] is not None:\n",
        "                self.dynamic_classifiers[i].partial_fit(x, y, self.classes)\n",
        "                self.dynamic_classifiers_dcir[i][y[0]] += 1\n",
        "        self.cc_array[cc_current_position] = x_new\n",
        "\n",
        "    def update_classifiers_weights(self):\n",
        "        number_of_current_classifiers = min(self.num_of_dynamic_classifiers, self.dc_indicator)\n",
        "        for i in range(number_of_current_classifiers):\n",
        "            self.dynamic_classifiers_weights[i] *= (\n",
        "                    1 - 1 / float(min(self.num_of_dynamic_classifiers, self.dc_indicator)))\n",
        "\n",
        "    def reinforcement_weight_adjustment(self, x_i):\n",
        "        x = x_i[0]\n",
        "        y = x_i[1][0]\n",
        "        # print(\"train on instance\", x.shape)\n",
        "        flag = True\n",
        "        for classe in self.classes:\n",
        "            flag = flag and self.dcir_values[classe] == 0\n",
        "        if flag:\n",
        "            return\n",
        "        if self.dcir_values[y] < 1 / float(self.num_of_classes):\n",
        "            for i in range(self.num_of_dynamic_classifiers):\n",
        "                if self.dynamic_classifiers[i] is not None:\n",
        "                    if self.dynamic_classifiers[i].predict(x)[0] == y:\n",
        "                        self.dynamic_classifiers_weights[i] *= (\n",
        "                                1 + 1 / float(self.num_of_dynamic_classifiers))\n",
        "                    else:\n",
        "                        self.dynamic_classifiers_weights[i] *= (\n",
        "                                1 - 1 / float(self.num_of_dynamic_classifiers))\n",
        "            if self.static_classifier is not None:\n",
        "                if self.static_classifier.predict(x)[0] == y:\n",
        "                    self.static_classifier_weight *= (\n",
        "                            1 + 1 / float(self.num_of_dynamic_classifiers))\n",
        "                else:\n",
        "                    self.static_classifier_weight *= (\n",
        "                            1 - 1 / float(self.num_of_dynamic_classifiers))\n",
        "\n",
        "    def normalize_weights(self):\n",
        "        classifiers_number = min(self.num_of_dynamic_classifiers, self.dc_indicator)\n",
        "        total_weight = self.static_classifier_weight\n",
        "        for i in range(classifiers_number):\n",
        "            total_weight += self.dynamic_classifiers_weights[i]\n",
        "        self.static_classifier_weight = self.static_classifier_weight / float(total_weight)\n",
        "        for i in range(classifiers_number):\n",
        "            self.dynamic_classifiers_weights[i] = self.dynamic_classifiers_weights[i] / float(total_weight)\n",
        "\n",
        "    def learning_procedure(self):\n",
        "        # initializing\n",
        "        processes_counter = 0\n",
        "        # cc_current_position = 0\n",
        "        # print(len(self.df))\n",
        "        # process\n",
        "        for index in range(self.stream_length):\n",
        "            x_new = self.stream.next_sample()\n",
        "            processes_counter += 1\n",
        "            if processes_counter > self.data_block_size and processes_counter % self.test_point == 1:\n",
        "                self.normalize_weights()\n",
        "                test_set = self.stream.next_sample(self.test_batch_size)\n",
        "                self.evaluate_batch(test_set)\n",
        "            if processes_counter < self.data_block_size:\n",
        "                self.cc_array[processes_counter - 1] = x_new\n",
        "            elif processes_counter == self.data_block_size:\n",
        "                self.cc_array[processes_counter - 1] = x_new\n",
        "                self.static_classifier, _ = self.create_new_base_classifier()\n",
        "                self.dc_indicator = 1\n",
        "                self.dynamic_classifiers[self.dc_indicator - 1] = self.static_classifier\n",
        "            else:\n",
        "                cc_current_position = (processes_counter - 1) % self.data_block_size\n",
        "                self.train_on_instance(x_new, cc_current_position)\n",
        "                cc_current_position = (cc_current_position + 1) % self.data_block_size\n",
        "                if cc_current_position == 0:\n",
        "                    self.dc_indicator += 1\n",
        "                    dynamic_classifier, dcir_d_v = self.create_new_base_classifier()\n",
        "                    if self.dc_indicator <= self.num_of_dynamic_classifiers:\n",
        "                        self.dynamic_classifiers[self.dc_indicator - 1] = dynamic_classifier\n",
        "                        self.dynamic_classifiers_dcir[self.dc_indicator - 1] = dcir_d_v\n",
        "                    else:\n",
        "                        self.shift_classifiers(dynamic_classifier, dcir_d_v)\n",
        "                    self.update_classifiers_weights()\n",
        "                    self.dcir()\n",
        "        for i in range(self.data_block_size):\n",
        "            x_new = self.cc_array[i]\n",
        "            self.train_on_instance(x_new, i)\n",
        "\n",
        "    def predict(self, test_set):\n",
        "        test_set_array = test_set[0]\n",
        "        number_of_current_classifiers = min(self.num_of_dynamic_classifiers, self.dc_indicator)\n",
        "        # print(self.static_classifier_weight)\n",
        "        predict_prop = self.static_classifier.predict_proba(test_set_array) * self.static_classifier_weight\n",
        "        for i in range(number_of_current_classifiers):\n",
        "            predict_prop += self.dynamic_classifiers[i].predict_proba(test_set_array) * \\\n",
        "                            self.dynamic_classifiers_weights[i]\n",
        "        # print(predict_prop)\n",
        "        res = np.argmax(predict_prop, axis=1)\n",
        "        # print(max_props_indices)\n",
        "        # res = self.classes[max_props_indices]\n",
        "        # res = self.classes_mask[res]\n",
        "        return res\n",
        "\n",
        "    def evaluate_batch(self, test_set):\n",
        "        res = self.predict(test_set)\n",
        "        # print(res)\n",
        "        real_val = test_set[1]\n",
        "        # print(real_val)\n",
        "        accuracy = ((res == real_val) * 1).sum()\n",
        "        self.accuracies.append(accuracy)\n",
        "        print(\"accuracy for test number\", len(self.accuracies), \" is:\", accuracy)\n",
        "\n",
        "\n",
        "stream = AGRAWALGenerator(classification_function=2, random_state=112, balance_classes=False)\n",
        "stream = HyperplaneGenerator()\n",
        "number_of_targets = 2\n",
        "stream.prepare_for_use()\n",
        "classifier = REDI(stream, number_of_targets, stream_length=100000)\n",
        "classifier.learning_procedure()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UopND8iZ0G4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from skmultiflow.trees.hoeffding_tree import HoeffdingTree\n",
        "\n",
        "\n",
        "class REDI:\n",
        "\n",
        "    def __init__(self, data_stream_file, target, data_block_size=500, num_of_dynamic_classifiers=10,\n",
        "                 selection_ratio=0.25):\n",
        "        df = pd.read_csv(data_stream_file)\n",
        "        print(\"Number of instances is: \", len(df))\n",
        "        self.real_classes = np.array(df[target].unique())\n",
        "        print(self.real_classes)\n",
        "        self.classes = np.arange(len(self.real_classes))\n",
        "        print(\"Number of classes is: \", len(self.real_classes))\n",
        "        self.classes_mask = {}\n",
        "        for i in range(len(self.classes)):\n",
        "            self.classes_mask[self.real_classes[i]] = i\n",
        "        df[target] = df.apply(lambda x: self.classes_mask[x[target]], axis=1)\n",
        "        self.target = target\n",
        "        self.df = df\n",
        "        # params\n",
        "        df = pd.read_csv(data_stream_file)\n",
        "        self.num_of_classes = len(self.classes)\n",
        "        self.data_block_size = data_block_size\n",
        "        self.num_of_dynamic_classifiers = num_of_dynamic_classifiers\n",
        "        self.selection_ratio = selection_ratio\n",
        "\n",
        "        # extra initializing\n",
        "        self.dynamic_classifiers_weights = np.ones(num_of_dynamic_classifiers) / float(num_of_dynamic_classifiers)\n",
        "        self.static_classifier_weight = 0.5\n",
        "        self.dynamic_classifiers = []\n",
        "        for i in range(num_of_dynamic_classifiers):\n",
        "            self.dynamic_classifiers.append(None)\n",
        "        self.dcir_values = {}\n",
        "        for classe in self.classes:\n",
        "            self.dcir_values[classe] = 0\n",
        "        self.dynamic_classifiers_dcir = []\n",
        "        for i in range(num_of_dynamic_classifiers):\n",
        "            dcir_classifier_values = {}\n",
        "            for classe in self.classes:\n",
        "                dcir_classifier_values[classe] = 0\n",
        "            self.dynamic_classifiers_dcir.append(dcir_classifier_values)\n",
        "        self.static_classifier = None\n",
        "\n",
        "        # Procedure initializing\n",
        "        self.dc_indicator = 0\n",
        "        self.cc_array = [None] * data_block_size\n",
        "        self.resampling_buffer = {}\n",
        "        for classe in self.classes:\n",
        "            self.resampling_buffer[classe] = pd.DataFrame(columns=self.df.columns)\n",
        "\n",
        "        # evaluation paramters\n",
        "        self.test_batch_size = 100\n",
        "        self.test_point = 1000\n",
        "        self.accuracies = []\n",
        "        self.aucs = []\n",
        "\n",
        "    def create_new_base_classifier(self):\n",
        "        r_n = self.cc_array[-int(self.selection_ratio * self.data_block_size):]\n",
        "        h_n = {}\n",
        "        h_d = {}\n",
        "        buffer_data = {}\n",
        "        x_train = []\n",
        "        y_train = []\n",
        "        for classe in self.classes:\n",
        "            h_n[classe] = 0\n",
        "            h_d[classe] = 0\n",
        "            buffer_data[classe] = []\n",
        "        for i in range(len(r_n)):\n",
        "            x_i = r_n[i]\n",
        "            self.reinforcement_weight_adjustment(x_i)\n",
        "            h_n[x_i[self.target]] += 1\n",
        "            h_d[x_i[self.target]] += 1\n",
        "            buffer_data[x_i[self.target]].append(x_i)\n",
        "        classifier = HoeffdingTree()\n",
        "        balanced_size = int(self.selection_ratio * self.data_block_size / self.num_of_classes)\n",
        "        for classe in self.classes:\n",
        "            if h_n[classe] < balanced_size:\n",
        "                extra_length = balanced_size - h_n[classe]\n",
        "                if len(self.resampling_buffer[classe]) < extra_length:\n",
        "                    extra_data = self.resampling_buffer[classe]\n",
        "                else:\n",
        "                    extra_data = self.resampling_buffer[classe][-extra_length:]\n",
        "                h_d[classe] += len(extra_data)\n",
        "                # print(\"extra data is\",extra_data)\n",
        "                for idx, row in extra_data.iterrows():\n",
        "                    numpy_row = row.to_numpy()\n",
        "                    x = numpy_row[:-1]\n",
        "                    y = numpy_row[-1]\n",
        "                    x_train.append(x)\n",
        "                    y_train.append(y)\n",
        "        for row in r_n:\n",
        "            numpy_row = row.to_numpy()\n",
        "            x = numpy_row[:-1]\n",
        "            y = numpy_row[-1]\n",
        "            x_train.append(x)\n",
        "            y_train.append(y)\n",
        "        classifier.partial_fit(x_train, y_train, self.classes)\n",
        "        dynamic_classifiers_dcir = {}\n",
        "        for classe in self.classes:\n",
        "            dynamic_classifiers_dcir[classe] = h_d[classe]\n",
        "        for classe in self.classes:\n",
        "            tmp_df = pd.DataFrame(buffer_data[classe])\n",
        "            self.resampling_buffer[classe] = self.resampling_buffer[classe].append(tmp_df)\n",
        "            self.resampling_buffer[classe] = self.resampling_buffer[classe][-balanced_size:]\n",
        "        return classifier, dynamic_classifiers_dcir\n",
        "\n",
        "    def dcir(self):\n",
        "        number_of_current_classifiers = min(self.num_of_dynamic_classifiers, self.dc_indicator)\n",
        "        dcir = {}\n",
        "        tot = 0\n",
        "        for classe in self.classes:\n",
        "            val = 0\n",
        "            for i in range(number_of_current_classifiers):\n",
        "                val += self.dynamic_classifiers_dcir[i][classe] * self.dynamic_classifiers_weights[i]\n",
        "            dcir[classe] = val\n",
        "            tot += val\n",
        "        for classe in self.classes:\n",
        "            dcir[classe] /= tot\n",
        "        self.dcir_values = dcir\n",
        "\n",
        "    def shift_classifiers(self, dynamic_classifier, dcir_d_v):\n",
        "        for i in range(self.num_of_dynamic_classifiers - 1):\n",
        "            self.dynamic_classifiers[i] = self.dynamic_classifiers[i + 1]\n",
        "            self.dynamic_classifiers_dcir[i] = self.dynamic_classifiers_dcir[i + 1]\n",
        "            self.dynamic_classifiers_weights[i] = self.dynamic_classifiers_weights[i + 1]\n",
        "        classifier_index = min(self.num_of_dynamic_classifiers, self.dc_indicator) - 1\n",
        "        self.dynamic_classifiers_weights[classifier_index] = 1 / float(self.num_of_dynamic_classifiers)\n",
        "        self.dynamic_classifiers_dcir[classifier_index] = dcir_d_v\n",
        "        self.dynamic_classifiers[classifier_index] = dynamic_classifier\n",
        "\n",
        "    def train_on_instance(self, x_new, cc_current_position):\n",
        "        x_i = self.cc_array[cc_current_position]\n",
        "        self.reinforcement_weight_adjustment(x_i)\n",
        "        numpy_row = x_i.to_numpy()\n",
        "        x = [numpy_row[:-1]]\n",
        "        y = [numpy_row[-1]]\n",
        "        self.static_classifier.partial_fit(x, y, self.classes)\n",
        "        for i in range(self.num_of_dynamic_classifiers):\n",
        "            if self.dynamic_classifiers[i] is not None:\n",
        "                self.dynamic_classifiers[i].partial_fit(x, y, self.classes)\n",
        "                self.dynamic_classifiers_dcir[i][y[0]] += 1\n",
        "        self.cc_array[cc_current_position] = x_new\n",
        "\n",
        "    def update_classifiers_weights(self):\n",
        "        number_of_current_classifiers = min(self.num_of_dynamic_classifiers, self.dc_indicator)\n",
        "        for i in range(number_of_current_classifiers):\n",
        "            self.dynamic_classifiers_weights[i] *= (\n",
        "                    1 - 1 / float(min(self.num_of_dynamic_classifiers, self.dc_indicator)))\n",
        "\n",
        "    def reinforcement_weight_adjustment(self, x_i):\n",
        "        numpy_row = x_i.to_numpy()\n",
        "        x = np.array([numpy_row[:-1]])\n",
        "        y = numpy_row[-1]\n",
        "        # print(\"train on instance\", x.shape)\n",
        "        flag = True\n",
        "        for classe in self.classes:\n",
        "            flag = flag and self.dcir_values[classe] == 0\n",
        "        if flag:\n",
        "            return\n",
        "        if self.dcir_values[y] < 1 / float(self.num_of_classes):\n",
        "            for i in range(self.num_of_dynamic_classifiers):\n",
        "                if self.dynamic_classifiers[i] is not None:\n",
        "                    if self.dynamic_classifiers[i].predict(x)[0] == y:\n",
        "                        self.dynamic_classifiers_weights[i] *= (\n",
        "                                1 + 1 / float(self.num_of_dynamic_classifiers))\n",
        "                    else:\n",
        "                        self.dynamic_classifiers_weights[i] *= (\n",
        "                                1 - 1 / float(self.num_of_dynamic_classifiers))\n",
        "            if self.static_classifier is not None:\n",
        "                if self.static_classifier.predict(x)[0] == y:\n",
        "                    self.static_classifier_weight *= (\n",
        "                            1 + 1 / float(self.num_of_dynamic_classifiers))\n",
        "                else:\n",
        "                    self.static_classifier_weight *= (\n",
        "                            1 - 1 / float(self.num_of_dynamic_classifiers))\n",
        "\n",
        "    def normalize_weights(self):\n",
        "        classifiers_number = min(self.num_of_dynamic_classifiers, self.dc_indicator)\n",
        "        total_weight = self.static_classifier_weight\n",
        "        for i in range(classifiers_number):\n",
        "            total_weight += self.dynamic_classifiers_weights[i]\n",
        "        self.static_classifier_weight = self.static_classifier_weight / float(total_weight)\n",
        "        for i in range(classifiers_number):\n",
        "            self.dynamic_classifiers_weights[i] = self.dynamic_classifiers_weights[i] / float(total_weight)\n",
        "\n",
        "    def learning_procedure(self):\n",
        "        # initializing\n",
        "        processes_counter = 0\n",
        "        # cc_current_position = 0\n",
        "        # print(len(self.df))\n",
        "        # process\n",
        "        for index, row in self.df.iterrows():\n",
        "            x_new = row\n",
        "            processes_counter += 1\n",
        "            if processes_counter > self.data_block_size and processes_counter % self.test_point == 1:\n",
        "                self.normalize_weights()\n",
        "                test_set = self.df[processes_counter:processes_counter + self.test_batch_size]\n",
        "                self.evaluate_batch(test_set)\n",
        "            if processes_counter < self.data_block_size:\n",
        "                self.cc_array[processes_counter - 1] = x_new\n",
        "            elif processes_counter == self.data_block_size:\n",
        "                self.cc_array[processes_counter - 1] = x_new\n",
        "                self.static_classifier, _ = self.create_new_base_classifier()\n",
        "                self.dc_indicator = 1\n",
        "                self.dynamic_classifiers[self.dc_indicator - 1] = self.static_classifier\n",
        "            else:\n",
        "                cc_current_position = (processes_counter - 1) % self.data_block_size\n",
        "                self.train_on_instance(x_new, cc_current_position)\n",
        "                cc_current_position = (cc_current_position + 1) % self.data_block_size\n",
        "                if cc_current_position == 0:\n",
        "                    self.dc_indicator += 1\n",
        "                    dynamic_classifier, dcir_d_v = self.create_new_base_classifier()\n",
        "                    if self.dc_indicator <= self.num_of_dynamic_classifiers:\n",
        "                        self.dynamic_classifiers[self.dc_indicator - 1] = dynamic_classifier\n",
        "                        self.dynamic_classifiers_dcir[self.dc_indicator - 1] = dcir_d_v\n",
        "                    else:\n",
        "                        self.shift_classifiers(dynamic_classifier, dcir_d_v)\n",
        "                    self.update_classifiers_weights()\n",
        "                    self.dcir()\n",
        "        for i in range(self.data_block_size):\n",
        "            x_new = self.cc_array[i]\n",
        "            self.train_on_instance(x_new, i)\n",
        "\n",
        "    def predict(self, test_set):\n",
        "        # print(self.static_classifier_weight)\n",
        "        test_set = test_set.drop(columns=self.target)\n",
        "        test_set_array = test_set.to_numpy()\n",
        "        number_of_current_classifiers = min(self.num_of_dynamic_classifiers, self.dc_indicator)\n",
        "        predict_prop = self.static_classifier.predict_proba(test_set_array) * self.static_classifier_weight\n",
        "        for i in range(number_of_current_classifiers):\n",
        "            predict_prop += self.dynamic_classifiers[i].predict_proba(test_set_array) * \\\n",
        "                            self.dynamic_classifiers_weights[i]\n",
        "        # print(predict_prop)\n",
        "        res = np.argmax(predict_prop, axis=1)\n",
        "        # print(max_props_indices)\n",
        "        # res = self.classes[max_props_indices]\n",
        "        # res = self.classes_mask[res]\n",
        "        return res\n",
        "\n",
        "    def evaluate_batch(self, test_set):\n",
        "        res = self.predict(test_set)\n",
        "        # print(res)\n",
        "        real_val = test_set[self.target].to_numpy()\n",
        "        # print(real_val)\n",
        "        accuracy = ((res == real_val) * 1).sum()\n",
        "        self.accuracies.append(accuracy)\n",
        "        print(\"accuracy for test number\", len(self.accuracies), \" is:\", accuracy)\n",
        "\n",
        "\n",
        "data_stream_file, target = \"https://raw.githubusercontent.com/scikit-multiflow/scikit-multiflow/master/src/skmultiflow/data/datasets/covtype.csv\", 'Cover_Type'\n",
        "# data_stream_file, target = 'covtype_mini.csv', 'Cover_Type'\n",
        "classifier = REDI(data_stream_file, target)\n",
        "classifier.learning_procedure()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}